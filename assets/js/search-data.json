{
  
    
        "post0": {
            "title": "But what are PyTorch DataLoaders really?",
            "content": "DataLoaders are magic. . You can often get away with using something magical. You can bury your head in the sand and ignore the mysterious methods behind it, all while enjoying the benefits that come from this magic. But at some point, either curiousity will get the better of you or you&#39;ll be missing the flexibility you need, and you&#39;ll want to try to demystify the sorcery. . In my opinion, the best libraries have an element of magic to them. They hide away some gory details with a little bit of polish and slight of hand that leave the world looking orderly and simple. The really great libraries allow you to peek behind the curtain at your own pace, slowly revealing the complexity and flexibility within. . I believe PyTorch is one of those libraries. It has lots of composable abstractions that you can learn about independenlty which neatly layer together to make a powerful, customisable and elegant framework. In this tutorial, we&#39;re going to dive into some of the details of PyTorch DataLoaders in the hopes of discovering how it works behind the scenes and how we can customise it to our liking. . I recommend you to run for this yourself as a Jupyter Notebook and create your own your Samplers and collate functions. All the code from this post is available on Github. . What&#39;s the plan? . PyTorch DataLoaders are great for iterating over batches of a Dataset like: . for xb, yb in dataloader: ... . where xb and yb are batches of your inputs and labels. . This tutorial is going to be about some of the more advanced features of DataLoaders which should explain what happens behind the scenes when you iterate over your dataloaders and help you customise different parts of that using PyTorch native features. . To be specific, we&#39;re going to go over custom collate functions and Samplers. . What are DataLoaders and Datasets? . For this tutorial to be useful, you should probably know what DataLoaders and Datasets are but I will refresh your memory. For a deeper dive, I recommend Jeremy Howard&#39;s tutorial What is torch.nn really ? and the PyTorch docs Writing Custom Datasets, DataLoaders and Transforms. . A quick refresher: PyTorch Datasets are just things that have a length and are indexable so that len(dataset) will work and dataset[index] will return a tuple of (x,y). . Here&#39;s a little example that&#39;s mostly taken from fastbook Chapter 4 to just quickly illustrate how simple a Dataset is: . So we&#39;ll create two lists for x and y values: . xs = list(range(10)) ys = list(range(10,20)) print(&#39;xs values: &#39;, xs) print(&#39;ys values: &#39;, ys) . xs values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] ys values: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19] . Then we use Python&#39;s zip function to combine them so dataset[index] returns (x,y) for that index: . dataset = list(zip(xs,ys)) dataset[0] # returns the tuple (x[0], y[0]) . (0, 10) . len(dataset) . 10 . Use __getitem__ and __len__ . We could also get the same functionality by using a class with the &quot;dunder/magic methods&quot; __getitem__ (for dataset[index] functionality) and __len__ (for len(dataset) functionality) . #collapse-show class MyDataset: def __init__(self, xs, ys): self.xs = xs self.ys = ys def __getitem__(self, i): return self.xs[i], self.ys[i] def __len__(self): return len(self.xs) . . dataset = MyDataset(xs, ys) dataset[2] # returns the tuple (x[2], y[2]) . (2, 12) . len(dataset) . 10 . &#160;Now use a DataLoader . Then we just wrap that in a DataLoader and we can iterate it but now they&#39;re magically tensors and we can use DataLoaders handy configurations like shuffling, batching, multi-processing, etc.: . from torch.utils.data import DataLoader for x, y in DataLoader(dataset): print(x,y) . tensor([0]) tensor([10]) tensor([1]) tensor([11]) tensor([2]) tensor([12]) tensor([3]) tensor([13]) tensor([4]) tensor([14]) tensor([5]) tensor([15]) tensor([6]) tensor([16]) tensor([7]) tensor([17]) tensor([8]) tensor([18]) tensor([9]) tensor([19]) . But the real fun is that we can get batches of these by setting batch_size: . for x, y in DataLoader(dataset, batch_size=2): print(x,y) . tensor([0, 1]) tensor([10, 11]) tensor([2, 3]) tensor([12, 13]) tensor([4, 5]) tensor([14, 15]) tensor([6, 7]) tensor([16, 17]) tensor([8, 9]) tensor([18, 19]) . And we can shuffle these batches by just setting shuffle=True: . for x, y in DataLoader(dataset, batch_size=2, shuffle=True): print(x,y) . tensor([2, 5]) tensor([12, 15]) tensor([7, 9]) tensor([17, 19]) tensor([1, 4]) tensor([11, 14]) tensor([0, 6]) tensor([10, 16]) tensor([8, 3]) tensor([18, 13]) . As you can see, it doesn&#39;t just shuffle the batches but instead, it shuffles the data and then batches. . OK... but can we customise this shuffling or batching??? Yes, we can customise the shuffling with a custom Sampler and we can customise the batching with a custom collate function. . Samplers . Every DataLoader has a Sampler which is used internally to get the indices for each batch. Each index is used to index into your Dataset to grab the data (x, y). You can ignore this for now, but DataLoaders also have a batch_sampler which returns the indices for each batch in a list if batch_size is greater than 1. . Don&#39;t worry if this is a bit confusing, it&#39;ll be more clear after a few examples hopefully: . Let&#39;s have a look at the internal .sampler property of a few DataLoaders and see how it changes when the DataLoader configurations change: . SequentialSampler . When shuffle=False(default) with batch_size=0, the sampler returns each index in 0,1,2,3,4... as you iterate. . default_sampler = DataLoader(dataset).sampler . So when we iterate over the sampler we should get the indices: . for i in default_sampler: #¬†iterating over the SequentialSampler print(i) . 0 1 2 3 4 5 6 7 8 9 . üëç . type(default_sampler) . torch.utils.data.sampler.SequentialSampler . We can see it has a sampler property internally which is a SequentialSampler. . Let&#39;s import SequentialSampler to see if we can use it ourself: . from torch.utils.data.sampler import SequentialSampler sampler = SequentialSampler(dataset) for x in sampler: print(x) . 0 1 2 3 4 5 6 7 8 9 . So it just returns indices as you iterate over it. Great, what about when shuffle=True? . RandomSampler . When shuffled, we should expect randomly shuffled indices: . random_sampler = DataLoader(dataset, shuffle=True).sampler for index in random_sampler: print(index) . 3 0 7 5 2 4 6 9 8 1 . So shuffle=True changes the sampler internally, which returns random indices each iteration. . type(random_sampler) . torch.utils.data.sampler.RandomSampler . We can see it&#39;s a RandomSampler so let&#39;s import that and use it ourself. . from torch.utils.data.sampler import RandomSampler random_sampler = RandomSampler(dataset) for x in random_sampler: print(x) . 9 7 0 3 2 4 6 5 8 1 . We can pass this in explicitly to a DataLoader using the sampler parameter like this: . dl = DataLoader(dataset, sampler=random_sampler) for i in dl.sampler: print(i) . 2 1 0 6 8 3 9 5 7 4 . So we&#39;ve seen that every DataLoader has a sampler internally which is either SequentialSampler or RandomSampler depending on the value of shuffle, and these are iterated over to get the indices of the Dataset to use. . Custom Sampler . That&#39;s great and all, but what if we want to customise the order of the data, other than shuffled or sequential. That&#39;s where custom Samplers come in. . From the docs: . Every Sampler subclass has to provide an __iter__ method, providing a way to iterate over indices of dataset elements, and a __len__ method that returns the length of the returned iterators. . So all we have to do to create a custom sampler is subclass Sampler and have a __iter__ method (for iterating through the indices) and a __len__ method for the length. . As a small toy example, say we wanted the first half of the dataset to always happen first, then the second half to happen later in training and we still to shuffle these two halfs independently: . . Note: Making the order of the data less random is generally bad for training neural networks but let&#8217;s forget about that for this example please. . #collapse-hide import random from torch.utils.data.sampler import Sampler class IndependentHalvesSampler(Sampler): def __init__(self, dataset): halfway_point = int(len(dataset)/2) self.first_half_indices = list(range(halfway_point)) self.second_half_indices = list(range(halfway_point, len(dataset))) def __iter__(self): random.shuffle(self.first_half_indices) random.shuffle(self.second_half_indices) return iter(self.first_half_indices + self.second_half_indices) def __len__(self): return len(self.first_half_indices) + len(self.second_half_indices) . . So we&#39;ve subclassed Sampler, we&#39;ve stored the both halves of the indices in two lists and when __iter__ is called (whenever the sampler is iterated over), it&#39;ll shuffle them independently and return an iterator of the two lists merged. . our_sampler = IndependentHalvesSampler(dataset) print(&#39;First half indices: &#39;, our_sampler.first_half_indices) print(&#39;Second half indices:&#39;, our_sampler.second_half_indices) . First half indices: [0, 1, 2, 3, 4] Second half indices: [5, 6, 7, 8, 9] . for i in our_sampler: print(i) . 1 2 4 3 0 7 9 8 5 6 . So you can see that a shuffled [0,1,2,3,4] happen first, and then a shuffled [5, 6, 7, 8, 9] happen last. . And we can pass it to a DataLoader like so: . dl = DataLoader(dataset, sampler=our_sampler) for xb, yb in dl: print(xb, yb) . tensor([4]) tensor([14]) tensor([0]) tensor([10]) tensor([1]) tensor([11]) tensor([3]) tensor([13]) tensor([2]) tensor([12]) tensor([7]) tensor([17]) tensor([8]) tensor([18]) tensor([5]) tensor([15]) tensor([6]) tensor([16]) tensor([9]) tensor([19]) . So we&#39;ve seen what&#39;s responsible for the order of the indices and we&#39;ve seen how PyTorch uses Samplers internally. We&#39;ve also seen how to create our own Sampler subclass and pass it to PyTorch&#39;s DataLoader. . A slight problem . You may have noticed a small problem above, if I make the batch size &gt; half of the dataset, some indices in the two halves of the dataset will be appear in the same batch. . batch_size=7 dl = DataLoader(dataset, batch_size=batch_size, sampler=our_sampler) for xb, yb in dl: print(xb, yb) . tensor([4, 2, 0, 3, 1, 5, 7]) tensor([14, 12, 10, 13, 11, 15, 17]) tensor([8, 6, 9]) tensor([18, 16, 19]) . This goes against our original goal because we wanted the first half of the dataset to always happen first. Let&#39;s say we want all batches in the first half to be separate from the second half... that&#39;s where batch_samplers come in. . BatchSampler . batch_size = 3 default_batch_sampler = DataLoader(dataset, batch_size=batch_size).batch_sampler for i, batch_indices in enumerate(default_batch_sampler): print(f&#39;Batch #{i} indices: &#39;, batch_indices) . Batch #0 indices: [0, 1, 2] Batch #1 indices: [3, 4, 5] Batch #2 indices: [6, 7, 8] Batch #3 indices: [9] . Internally, PyTorch uses a BatchSampler to chunk together the indices into batches. We can make custom Samplers which return batches of indices and pass them using the batch_sampler argument. This is a bit more powerful in terms of customisation than sampler because you can choose both the order and the batches at the same time. . For example, say for some reason you wanted to only batch certain things together (like only if they&#39;re the same length), or if you wanted to show some examples more often than other, a custom BatchSampler is great for this. . So rather than returning each index separately, the batch_sampler iterates through batches of indices. PyTorch uses the sampler internally to select the order, and the batch_sampler to batch together batch_size amount of indices. . type(default_batch_sampler) . torch.utils.data.sampler.BatchSampler . We can see it&#39;s a BatchSampler internally. Let&#39;s import this to see what it does: . from torch.utils.data.sampler import BatchSampler . Here&#39;s the BatchSampler docstring: . print(BatchSampler.__doc__) . Wraps another sampler to yield a mini-batch of indices. Args: sampler (Sampler): Base sampler. batch_size (int): Size of mini-batch. drop_last (bool): If ``True``, the sampler will drop the last batch if its size would be less than ``batch_size`` Example: &gt;&gt;&gt; list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False)) [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] &gt;&gt;&gt; list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True)) [[0, 1, 2], [3, 4, 5], [6, 7, 8]] . So you can initialise it with a Sampler, batch_size and drop_last (whether to remove the last batch), and it will return batches of indices when you iterate over it. . batch_sampler = BatchSampler(our_sampler, batch_size=2, drop_last=False) for i, batch_indices in enumerate(batch_sampler): print(f&#39;Batch #{i} indices: &#39;, batch_indices) . Batch #0 indices: [2, 4] Batch #1 indices: [1, 3] Batch #2 indices: [0, 9] Batch #3 indices: [8, 6] Batch #4 indices: [5, 7] . As you can see, we can pass our custom Sampler to BatchSampler to control the order, and leave it responsible for batching the indices. We can then pass it to a DataLoader in the batch_sampler argument. . Custom Batch Sampler . Similar to a custom sampler, you can also create a batch_sampler. Why? If for some reason you wanted to only batch certain things together (like only if they&#39;re the same length), or if you wanted to show some examples more often than others, a custom BatchSampler is great for this. . To create a custom batch_sampler, we just do the same as we did with a custom Sampler but our iterator returns batches of indices, rather than individual indices. . Let&#39;s create a BatchSampler which only batches together values from the first half of our dataset. . def chunk(indices, chunk_size): return torch.split(torch.tensor(indices), chunk_size) class EachHalfTogetherBatchSampler(Sampler): def __init__(self, dataset, batch_size): halfway_point = len(dataset) // 2 self.first_half_indices = list(range(halfway_point)) self.second_half_indices = list(range(halfway_point, len(dataset))) self.batch_size = batch_size def __iter__(self): random.shuffle(self.first_half_indices) random.shuffle(self.second_half_indices) first_half_batches = chunk(self.first_half_indices, self.batch_size) second_half_batches = chunk(self.second_half_indices, self.batch_size) combined = list(first_half_batches + second_half_batches) combined = [batch.tolist() for batch in combined] random.shuffle(combined) return iter(combined) def __len__(self): return (len(self.first_half_indices) + len(self.second_half_indices)) // self.batch_size . So we&#39;ve subclassed Sampler, we&#39;ve stored the indices in two lists (as before) and when __iter__ is called (whenever the batch_sampler is iterated over), it&#39;ll first batch them using a method we&#39;ve called chunk. . Then we merge the batches and finally, we shuffle the batches and return an iterator of them. . batch_size = 2 each_half_together_batch_sampler = EachHalfTogetherBatchSampler(dataset, batch_size) for x in each_half_together_batch_sampler: print(x) . [1] [5] [8, 6] [7, 9] [4, 2] [0, 3] . Great, as we hoped, none of the first and second half are batched together. . And now, we can pass this to DataLoader using the batch_sampler argument: . for i, (xb,yb) in enumerate(DataLoader(dataset, batch_sampler=each_half_together_batch_sampler)): print(f&#39;Batch #{i}. x{i}:&#39;, xb) print(f&#39; y{i}:&#39;, yb) . Batch #0. x0: tensor([7, 5, 8]) y0: tensor([17, 15, 18]) Batch #1. x1: tensor([9, 6]) y1: tensor([19, 16]) Batch #2. x2: tensor([2, 0]) y2: tensor([12, 10]) Batch #3. x3: tensor([3, 1, 4]) y3: tensor([13, 11, 14]) . Ok, great. That&#39;s how PyTorch chooses which elements in my Dataset to batch together... but where does that batching actually happen? And can we customise that ? . Custom Collate Functions . Internally, PyTorch uses a Collate Function to combine the data in your batches together (*see note). By default, a function called default_collate checks what type of data your Dataset returns and tries it&#39;s best to combine them data into a batch like a (x_batch, y_batch). . . Note: For simplicity, we&#8217;re going to assume automatic batching is enabled. See the PyTorch docs for details about collate functions when automatic batching is disabled: https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler . But what if we had custom types or multiple different types of data which we wanted to handle which default_collate couldn&#39;t merge? We could edit our Dataset so that they are mergable and that&#39;s solves some of the types issues BUT what if how we merged them depended on &#39;batch-level&#39; information like the largest value in the batch. . . Note: For other fancy uses of custom collate functions, there&#8217;s some cool examples in the popular huggingface/transformers library. . For problems like these, custom collate functions are a handy way of solving them. . From the PyTorch docs: . Users may use customized collate_fn to achieve custom batching, e.g., collating along a dimension other than the first, padding sequences of various lengths, or adding support for custom data types. . Input to your collate function . You will need to match your custom collate function with the output of indexing your Dataset. If you dataset returns a tuple (x, y) when indexed into (like dataset[0]), then your collate function will need to take a list of tuples like [(x0,y0), (x4,y4), (x2,y2)... ] which is batch_size in length. . One thing that custom collate functions are often used for is for padding variable length batches. So let&#39;s change our dataset so that each x is a list, and they&#39;re all different sizes. . xs = list([torch.randint(0, 10, (x,)) for x in range(1, 11)]) . xs . [tensor([5]), tensor([3, 8]), tensor([7, 7, 1]), tensor([2, 6, 5, 7]), tensor([5, 1, 4, 0, 7]), tensor([0, 1, 2, 1, 4, 9]), tensor([2, 3, 0, 9, 3, 4, 4]), tensor([2, 8, 8, 5, 7, 8, 2, 8]), tensor([5, 4, 0, 2, 1, 9, 5, 3, 2]), tensor([9, 2, 4, 7, 4, 3, 6, 6, 6, 7])] . dataset = list(zip(xs,ys)) dataset[5] . (tensor([0, 1, 2, 1, 4, 9]), 15) . Now, if we try with the defaul collate function, it&#39;ll raise a RuntimeError. . try: for xb, yb in DataLoader(dataset, batch_size=2): print(xb) except RuntimeError as e: print(&#39;RuntimeError: &#39;, e) . RuntimeError: stack expects each tensor to be equal size, but got [1] at entry 0 and [2] at entry 1 . With variable sized xs and a custom collate function, we could pad them to match the longest in the batch using torch.nn.utils.rnn.pad_sequence. . from torch.nn.utils.rnn import pad_sequence def pad_x_collate_function(batch): # batch looks like [(x0,y0), (x4,y4), (x2,y2)... ] xs = [sample[0] for sample in batch] ys = [sample[1] for sample in batch] #¬†If you want to be a little fancy, you can do the above in one line #¬†xs, ys = zip(*samples) xs = pad_sequence(xs, batch_first=True, padding_value=0) return xs, torch.tensor(ys) . And now, we can pass this pad_x_collate_function to collate_fn in DataLoader and it will pad each batch. . for xb, yb in DataLoader(dataset, batch_size=2, collate_fn=pad_x_collate_function): print(xb) . tensor([[5, 0], [3, 8]]) tensor([[7, 7, 1, 0], [2, 6, 5, 7]]) tensor([[5, 1, 4, 0, 7, 0], [0, 1, 2, 1, 4, 9]]) tensor([[2, 3, 0, 9, 3, 4, 4, 0], [2, 8, 8, 5, 7, 8, 2, 8]]) tensor([[5, 4, 0, 2, 1, 9, 5, 3, 2, 0], [9, 2, 4, 7, 4, 3, 6, 6, 6, 7]]) . Here is it with shuffle=True. . for xb, yb in DataLoader(dataset, shuffle=True, batch_size=2, collate_fn=pad_x_collate_function): print(&#39;xs: &#39;, xb) print(&#39;ys: &#39;, yb) . xs: tensor([[9, 2, 4, 7, 4, 3, 6, 6, 6, 7], [2, 8, 8, 5, 7, 8, 2, 8, 0, 0]]) ys: tensor([19, 17]) xs: tensor([[2, 6, 5, 7], [5, 0, 0, 0]]) ys: tensor([13, 10]) xs: tensor([[5, 4, 0, 2, 1, 9, 5, 3, 2], [2, 3, 0, 9, 3, 4, 4, 0, 0]]) ys: tensor([18, 16]) xs: tensor([[5, 1, 4, 0, 7], [3, 8, 0, 0, 0]]) ys: tensor([14, 11]) xs: tensor([[7, 7, 1, 0, 0, 0], [0, 1, 2, 1, 4, 9]]) ys: tensor([12, 15]) . Another slight problem . But there&#39;s a bit of an issue, some of the smaller values look the they have too much padding. Luckily, we&#39;ve already created something that&#39;ll help here. We can use our EachHalfTogetherBatchSampler custom batch_sampler so that the first and second half are batched separately. . each_half_together_batch_sampler = EachHalfTogetherBatchSampler(dataset, batch_size=2) for xb, yb in DataLoader(dataset, collate_fn=pad_x_collate_function, batch_sampler=each_half_together_batch_sampler): print(xb) . tensor([[7, 7, 1, 0, 0], [5, 1, 4, 0, 7]]) tensor([[5, 4, 0, 2, 1, 9, 5, 3, 2], [0, 1, 2, 1, 4, 9, 0, 0, 0]]) tensor([[2, 3, 0, 9, 3, 4, 4, 0], [2, 8, 8, 5, 7, 8, 2, 8]]) tensor([[2, 6, 5, 7], [5, 0, 0, 0]]) tensor([[9, 2, 4, 7, 4, 3, 6, 6, 6, 7]]) tensor([[3, 8]]) . And there we go, you can see the zero padding (but not too much!) at the end of each batch. . Conclusion . I recommend you to run for this yourself and create your own your Samplers and collate functions. All the code from this post is available on Github. . I personally love learning about new parts of PyTorch and finding ways to interact with them. What do you think about these styles of explorations? Did you learn a bit about DataLoaders, Samplers and collate functions by reading this article? If so, feel free to share it, and you‚Äôre also more than welcome to contact me (via Twitter) if you have any questions, comments, or feedback. . Thanks for reading! :rocket: . Follow me on Twitter here for more stuff like this. . Follow @_ScottCondron .",
            "url": "https://www.scottcondron.com/jupyter/visualisation/audio/2020/12/02/dataloaders-samplers-collate.html",
            "relUrl": "/jupyter/visualisation/audio/2020/12/02/dataloaders-samplers-collate.html",
            "date": " ‚Ä¢ Dec 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Building Tools to Interact With Your Data",
            "content": "What are we doing? . Data sitting on a computer somewhere is pretty dull. If you are working with data, it&#39;s a good idea to find lots of ways to interact with it. If you work with a type of data that is specific to your field, there&#39;ll likely be lots of ways you can think of to interact with it. . For example if it&#39;s images, look at them. If you transform your data for any reason, look at them before and after the transformation. It sounds obvious but it can be overlooked by machine learning engineers / data scientists because building tools or bespoke visualisations to interact with data can sometimes feel out of the scope of their responsibilities. . Ok, preaching aside, let&#39;s create something that will help people who work with audio within Jupyter notebooks to interact with it. This will allow people working with audio data in Python to listen to their audio alongside any plots they have for the audio e.g. the output of a neural network. . The end goal is to have an interactive audio plot for interacting with audio visualisation plots like this tweet. Credit to this StackOverflow post for sharing a HoloViews audio plot with a playhead. Thanks to @HoloViz_org @Panel_org and this StackOverflow post (https://t.co/gu907C8woB), I was able to make an interactive audio plotter in Jupyter without having to resort to Javascript hacks. Here is panel&#39;s Audio pane docs: https://t.co/AQ8cUtSUnB pic.twitter.com/SmgxpH3yuM . &mdash; Scott Condron (@_ScottCondron) June 4, 2020 . Here&#39;s a version of the final widget that works in a browser. Note: there&#39;s a clickable plot if you run it yourself. . &#160;Hear and look at Audio . First things first, we want to be able to hear the audio. Conveniently, IPython comes with lots of out-of-the-box ways to display data. Here&#39;s one for audio: . #collapse-show from IPython import display audio_path = &quot;./my_icons/blah.wav&quot; display.Audio(filename=audio_path) . . Your browser does not support the audio element. Although this lets us hear the audio, what if we want to see it? Let&#39;s first look at what&#39;s inside it: . #collapse-show from scipy.io import wavfile sr, wav_data = wavfile.read(audio_path) print(sr) print(wav_data.shape) . . 48000 (775922, 2) . This shows the sample rate is 48000Hz and it has 775922 samples for 2 channels. . wav_data[:,0] # first channel . array([-2, -3, 0, ..., -3, -1, 0], dtype=int16) . Seeing audio in a big numpy array isn&#39;t very useful. But what if we plot the values: . #collapse-show %matplotlib inline import matplotlib.pyplot as plt plt.plot(wav_data) plt.show() . . The two channels are on top of eachother. We can split them like so: . #collapse-show fig, axs = plt.subplots(2) axs[0].plot(wav_data[:,0]) axs[1].plot(wav_data[:,1]) plt.show() . . Although this is nice, I&#39;d like to have the x-axis be seconds rather than samples. We can use numpy.linspace to do this. It just gives use evenly spaced numbers between start and end, and we can decide how many numbers. . The duration is just the number of samples divided by the sample rate, and we want the same number of points (to match our y axis). . #collapse-show import numpy as np fig, axs = plt.subplots(2) duration = len(wav_data)/sr x = np.linspace(0, duration, len(wav_data)) axs[0].plot(x, wav_data[:,0]) axs[1].plot(x, wav_data[:,1]) # audio channel 1 plt.show() . . Ok, that&#39;s better but is there any better way to view audio than using the amplitude of the waveform?? . &#160;Spectrograms . Smarter people than me came up with viewing audio frequencies rather than amplitudes. &#39;Spectrograms&#39; of audio are used to display this. They are visualisations of the frequency changes over time. We&#39;ll just use one channel from now on for simplicity. . #collapse-show audio_data = wav_data[:,0] # just use one channel from now on plt.specgram(audio_data, Fs=sr) plt.show() display.Audio(audio_path) . . Your browser does not support the audio element. We can do the same thing using scipy to first get the spectogram and then use matplotlib to plot it with a colormesh using the log of the spectrogram. . #collapse-show from scipy.signal import spectrogram f, t, sxx = spectrogram(audio_data, sr) plt.pcolormesh(t, f, np.log10(sxx)) plt.show() . . Add More Interactivity . That&#39;s getting us close to what we want, but what we really want is to be able to interact with the plot and hear the audio at the point we interact with. . For more interactivity, we&#39;re going to reach for a different tool other than matplotlib and IPython.display. Holoviews and Panel by the Anaconda team are very nice for custom interactivity. Conveniently for us, Panel&#39;s Audio pane and Holoviews Image component play nicely together and allow us do more interactive viusalisations. . #hide_output import holoviews as hv import panel as pn hv.extension(&quot;bokeh&quot;, logo=False) spec_gram = hv.Image((t, f, np.log10(sxx)), [&quot;Time (s)&quot;, &quot;Frequency (hz)&quot;]).opts(width=600) audio = pn.pane.Audio(audio_data, sample_rate=sr, name=&#39;Audio&#39;, throttle=500) pn.Column(spec_gram, audio) . Here we create a Image the same way we did with matplotlib plt.pcolormesh and the pn.pane.Audio using the first channel of the audio_data we got from scipy.io.wavfile.read(audio_path). Finally, we put them together in a pn.Column so that the spectrogram is displayed above the audio player. . Add Playhead . We want the playhead to update when the time changes while you&#39;re playing it. To do this, We&#39;ll use a Holoviews DynamicMap. It sounds complicated but put simply, it links a stream with a callback function. . In this case the stream we&#39;re using is the Stream from audio.param.time and the callback update_playhead we create that returns a Vline (the playhead). We use * operator to overlay the image with the returned Vline playhead. . #hide_output def update_playhead(time): return hv.VLine(time) dmap_time = hv.DynamicMap(update_playhead, streams=[audio.param.time]).opts(width=600) pn.Column(audio, spec_gram * dmap_time) . . Note: The slider underneath is because of how I made it work on a static HTML web page. If you run it yourself, there&#8217;ll be no slider. . Add Click to Update Playhead . That works great, but we also want to be able to click the plot and update the playhead. We do this by merging two streams to trigger one update_playhead callback within the DynamicMap. The SingleTap stream captures when the plot is clicked, and we use Params to update time to t for the merged callback. Within the update_playhead callback, we just check if x (the x position of the click) is None, if it is we use the time. . #collapse-show def update_playhead(x,y,t): if x is None: return hv.VLine(t) else: audio.time = x return hv.VLine(x) tap_stream = hv.streams.SingleTap(transient=True) time_play_stream = hv.streams.Params(parameters=[audio.param.time], rename={&#39;time&#39;: &#39;t&#39;}) dmap_time = hv.DynamicMap(update_playhead, streams=[time_play_stream, tap_stream]) out = pn.Column(audio, spec_gram * dmap_time) . . . Note: This will work when you run the notebook yourself, but the interactivity is lost when hosted on a static HTML web page. You can link it with a Python backend, but that&#8217;s not happening here because it requires a bit of work that I haven&#8217;t done. . All the code in one place . #collapse_hide from scipy.signal import spectrogram import holoviews as hv import panel as pn from scipy.io import wavfile hv.extension(&quot;bokeh&quot;, logo=False) sr, wav_data = wavfile.read(audio_path) audio_data = wav_data[:,0] # first channel f, t, sxx = spectrogram(audio_data, sr) spec_gram = hv.Image((t, f, np.log10(sxx)), [&quot;Time (s)&quot;, &quot;Frequency (hz)&quot;]).opts(width=600) audio = pn.pane.Audio(wav_data[:,0], sample_rate=sr, name=&#39;Audio&#39;, throttle=500) def update_playhead(x,y,t): if x is None: return hv.VLine(t) else: audio.time = x return hv.VLine(x) tap_stream = hv.streams.SingleTap(transient=True) time_play_stream = hv.streams.Params(parameters=[audio.param.time], rename={&#39;time&#39;: &#39;t&#39;}) dmap_time = hv.DynamicMap(update_playhead, streams=[time_play_stream, tap_stream]) out = pn.Column( audio, (spec_gram * dmap_time)) . . Bonus: Make it work on a static HTML page . I won&#39;t really dive into this but you can remove the need for a Python server by using jslink to rely on your browser&#39;s Javascript alone. I&#39;d be interested to hear if there was a nicer way to do this, and how easy it would be to add a click event. That&#39;s actually how I made the above plots display in your browser. . #hide_output from bokeh.resources import INLINE slider = pn.widgets.FloatSlider(end=duration) line = hv.VLine(0) slider.jslink(audio, value=&#39;time&#39;, bidirectional=True) slider.jslink(line, value=&#39;glyph.location&#39;) pn.Column(spec_gram * line, slider, audio).save(&#39;redo&#39;, embed=True, resources=INLINE) . Play with it yourself! . You can view and run all the code yourself from here. . I personally love learning about these kind of visualisations and finding ways to creating interactivity. What do you think about these type of widgets for interacting with data? Did you learn a bit about creating interactive visualisations in Python by reading this article? If so, feel free to share it, and you‚Äôre also more than welcome to contact me (via Twitter) if you have any questions, comments, or feedback. . Thanks for reading! :rocket: . Follow me on Twitter here for more stuff like this. . Follow @_ScottCondron .",
            "url": "https://www.scottcondron.com/jupyter/visualisation/audio/2020/10/21/interactive-audio-plots-in-jupyter-notebook.html",
            "relUrl": "/jupyter/visualisation/audio/2020/10/21/interactive-audio-plots-in-jupyter-notebook.html",
            "date": " ‚Ä¢ Oct 21, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Interact with PyTorch layers using Jupyter Widgets",
            "content": "What are we doing? . Sometimes we want to see inputs and outputs of PyTorch layers to build an intuition of what they do. If I&#39;ve read the docs and put a few tensors through the layer while checking the inputs and outputs shapes, generally that&#39;s enough. . But sometimes there&#39;s weird parameters that I can&#39;t get my head around or I just want to see it working, so building interactive widgets helps me grow my understanding. . So in this post I&#39;ll show you how I built an interactive widget to explore PyTorch&#39;s ConvTranspose1d, while explaining a bit about the layer itself. We&#39;ll use Anacondas&#39;s HoloViz tools (Holoviews, Panel and Bokeh) for the plotting and interactivity. . The end goal is to have a interactive plot for interacting with ConvTranspose1d parameters and seeing the output like this tweet. Creating widgets in Jupyter is a good way to interact with @PyTorch layers.I wanted to intuitively know how padding and output padding worked in ConvTranspose1d so I created this widget with @HoloViews and @Panel_org to control the parameters and visualise the output tensor. pic.twitter.com/LQfHb3cTUq . &mdash; Scott Condron (@_ScottCondron) September 21, 2020 . Introduction to Transposed Convolutions . Before learning about Transposed Convolutions, you&#39;re best learning about Convolutions first. CS231n is a great resource for learning about them. . As you may know, Convolutions are often used to efficiently reduce a dimensions of the input in neural networks. In the case of image classification tasks, they are used to efficiently reduce an input image to a single class score. . Transposed Convolutions are useful when you want to grow your network in a certain dimension. For example, say you have a image segmentation task, in which you want a class prediction per pixel, you can use strided Convolutions to reduce the dimensions and then grow the dimensions back to their original sizel with Transposed Convolutions. This is done in U-net style architectures. . Conveniently, PyTorch has implemented ConvTranspose1d such that if it has the same input parameters as Conv1d and if you pass a tensor through both, the output tensor will be the same shape as the input tensor (provided you set output_padding correclty). . . Imports . #collapse-hide import torch import torch.nn as nn from panel.interact import interact from panel import widgets import panel as pn from IPython.display import display import holoviews as hv from holoviews import opts import numpy as np hv.extension(&#39;bokeh&#39;, logo=False) . . Create an image from a PyTorch Tensor . Firstly, to create an image from a 2d numpy array, we&#39;ll use the Holoviews library denoted hv here. . There&#39;s a few little bits here to make it nicer but hv.Image(out) would have worked fine. . You can skip this if you&#39;re not interested in the visualisation details. We set the bounds so we have correct axes. We use * operator to overlay the image with hv.Labels(image) so that the values are printed on top of each pixel. We set the vdims to a fixed range so that colours don&#39;t change between updates. We set the width to change depending on the number of pixels so it&#39;s easier to watch it grow. L‚Äπastly, we return the image in a HoloViews pane with linked_axes=False so that each plot gets it&#39;s own axes. . #collapse-show hv.extension(&#39;bokeh&#39;, logo=False) output_dim = 4 def image(out, feature_dim=output_dim, title=&#39;&#39;, xlabel=&#39;Sequence Dimension&#39;, ylabel=&#39;Feature Dimension&#39;): output_image = hv.Image(out, vdims=hv.Dimension(&#39;z&#39;, range=(0, 100)), bounds=(0, 0, out.shape[-1], feature_dim)) layout = output_image * hv.Labels(output_image) layout.opts( hv.opts.Image(cmap=&#39;PiYG&#39;, xlabel=xlabel, ylabel=ylabel, title=title, width=50*out.shape[-1]) ) return pn.pane.HoloViews(layout, linked_axes=False) . . Create Predictable Input Data . Then we create some synthetic input data, I could create random data but instead I create predictable data so it&#39;s easier to think about. . #collapse-show seq_len = 5 input_dim = 6 input_data = torch.tensor([list(range(1, seq_len+1))]*input_dim).double() image(input_data.detach().numpy(), feature_dim=input_dim) . . Input Data . . Another thing I sometimes do is set the weights of the layer itself when doing these visualisations. These would be randomly initialised and then learned by the network in practice. . #collapse-show kernel_size = 7 weights = torch.tensor([[list(range(i, i+kernel_size)) for i in range(output_dim)]]*input_dim).double() assert weights.shape == (input_dim, output_dim, kernel_size) print(&#39;Weights Shape [in,out,k]: &#39;, list(weights.shape)) bias = torch.tensor(list(range(output_dim))).double() print(&#39;Bias: &#39;, bias) . . Weights Shape [in,out,k]: [6, 4, 7] Bias: tensor([0., 1., 2., 3.], dtype=torch.float64) . For each of the input channels, we have learned filters of shape Kernel Size * Output Channels. Here&#39;s one of them: . #collapse-show image(weights[0].detach().numpy(), xlabel=&#39;Kernel Size&#39;, ylabel=&#39;Output Channels&#39;) . . &#160;Weights . . &#160;Weights Shape . Interactive Sliders . To have sliders dynamically update the plot, we&#39;ll use widgets and interact from panel. . &#160;@interact and widgets . The @interact decorator allows you to create widgets and the visualisation that depends on them at the same time. So in this case, we want widgets to control the different parameters of ConvTranspose1d. As the widgets change, conv_out is called and returns the image we defined before. . We use widgets.IntSlider to explicitly create the widgets for each parameter in the conv_transpose_out function. One interesting thing to note is that use_bias=True automatically creates a checkbox for us. Finally, we return a pn.Column to compose the input and output images. . #collapse-show hv.extension(&#39;bokeh&#39;, logo=False) input_dim = 6 output_dim = 4 kernel_size = 7 seq_len = 5 stride = 2 dilation = 1 use_bias = True @interact(padding= widgets.IntSlider(name=&#39;Padding&#39;, start=0,end=5, step=1, value=1), output_padding= widgets.IntSlider(name=&#39;Output Padding&#39;, start=0,end=3, step=1, value=0), seq_len= widgets.IntSlider(name=&#39;Input Sequence Length&#39;, start=1,end=10,step=1, value=seq_len), kernel_size= widgets.IntSlider(name=&#39;Kernel Size&#39;, start=3,end=5, step=1, value=kernel_size), stride= widgets.IntSlider(name=&#39;Stride&#39;, start=1,end=5, step=1, value=stride), use_bias=True ) def conv_transpose_out(padding, output_padding, seq_len, kernel_size, stride, use_bias): if output_padding &gt; stride: return &#39;Output Padding needs to be less than or equal to Stride&#39; conv_t = nn.ConvTranspose1d(input_dim, output_dim, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=output_padding, bias=use_bias) input_data = torch.tensor([list(range(1, seq_len+1))]*input_dim).double() conv_t.weight.data = weights[:,:,:kernel_size] if use_bias: conv_t.bias.data = bias in_tensor = input_data[None,:,:seq_len] in_seq_len = in_tensor.shape[-1] out = conv_t(in_tensor).squeeze(0).detach().numpy() in_image = image(input_data.detach().numpy(), input_data.shape[0], &#39;Input&#39;) out_image = image(out, out.shape[0], &#39;ConvTranspose1d Output&#39;) return pn.Column(out_image) . . If you run this code yourself, you can interact with all parameters together. To be able to show this on a static HTML Github Pages blog, I needed to reduce the space of the sliders so here&#39;s how padding and output padding affect the size of the output. . &#160;Padding and Output Padding . You can see the padding reduces the size of the sequence dimension. As described in the PyTorch documentation: . . Note: The padding argument effectively adds &quot;dilation * (kernel_size - 1) - padding&quot; amount of zero padding to both sizes of the input . The output padding arguement adds padding to one side. From the PyTorch documentation: . . Note: When stride &gt; 1, Conv1d maps multiple input shapes to the same output shape. output_padding is provided to resolve this ambiguity by effectively increasing the calculated output shape on one side. . Kernel Size and Stride . And here&#39;s how the kernel size and stride affect the sequence dimension. You can see that a bigger stride increases the size of the sequence dimension, as opposed to decreasing it like with regular convolutions. . Play with it yourself! . If you&#39;d like to run this yourself or create your own visualisations with different layers, all the code from this post is available on Github. . I personally love learning about new layers in PyTorch and finding ways to interact with them visually. What do you think about these styles of visualisations? Did you learn a bit about Transposed Convolutions or creating interactive visualisations in Python by reading this article? If so, feel free to share it, and you‚Äôre also more than welcome to contact me (via Twitter) if you have any questions, comments, or feedback. . Thanks for reading! :rocket: . Follow me on Twitter here for more stuff like this. . Follow @_ScottCondron .",
            "url": "https://www.scottcondron.com/jupyter/visualisation/ai/deep%20learning/2020/09/25/interact-with-pytorch-layers-with-jupyter-widgets.html",
            "relUrl": "/jupyter/visualisation/ai/deep%20learning/2020/09/25/interact-with-pytorch-layers-with-jupyter-widgets.html",
            "date": " ‚Ä¢ Sep 25, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Python itertools",
            "content": "&#160;Pre-requisits . You can pass functions as variables . def add_two(x): return x+2 def do_something_then_add_three(something_to_do_first, x): # first call something_to_do_first with the input, then add 3 return something_to_do_first(x) + 3 # We pass add_two (note the lack of brackets beside it) do_something_then_add_three(add_two, 0) . 5 . An iterator is an object representing a stream of data. You can call next on an iterator to get the next value. . from string import ascii_lowercase ascii_lowercase . &#39;abcdefghijklmnopqrstuvwxyz&#39; . iter(ascii_lowercase) . &lt;str_iterator at 0x7fad0bcb2d10&gt; . alphabet_iterator = iter(ascii_lowercase) next(alphabet_iterator) . &#39;a&#39; . next(alphabet_iterator) . &#39;b&#39; . def add_underscore(x,y): return f&#39;{x}_{y}&#39; . import itertools alphabet_iterator = iter(ascii_lowercase) . my_list = [1,3,5,6] list(itertools.islice(my_list, 3)) . [1, 3, 5] . Say we want to create a list of tuples with ( position_in_alphabet, letter ) starting at (1, &#39;a&#39;) like . [(1, &#39;a&#39;), (2, &#39;b&#39;), (3, &#39;c&#39;)] . [(1, &#39;a&#39;), (2, &#39;b&#39;), (3, &#39;c&#39;)] . alphabet_tuples = [] for i in range(len(ascii_lowercase)): alphabet_tuples.append((i+1, ascii_lowercase[i])) alphabet_tuples . [(1, &#39;a&#39;), (2, &#39;b&#39;), (3, &#39;c&#39;), (4, &#39;d&#39;), (5, &#39;e&#39;), (6, &#39;f&#39;), (7, &#39;g&#39;), (8, &#39;h&#39;), (9, &#39;i&#39;), (10, &#39;j&#39;), (11, &#39;k&#39;), (12, &#39;l&#39;), (13, &#39;m&#39;), (14, &#39;n&#39;), (15, &#39;o&#39;), (16, &#39;p&#39;), (17, &#39;q&#39;), (18, &#39;r&#39;), (19, &#39;s&#39;), (20, &#39;t&#39;), (21, &#39;u&#39;), (22, &#39;v&#39;), (23, &#39;w&#39;), (24, &#39;x&#39;), (25, &#39;y&#39;), (26, &#39;z&#39;)] . list(zip(count(start=1), ascii_lowercase)) . [(1, &#39;a&#39;), (2, &#39;b&#39;), (3, &#39;c&#39;), (4, &#39;d&#39;), (5, &#39;e&#39;), (6, &#39;f&#39;), (7, &#39;g&#39;), (8, &#39;h&#39;), (9, &#39;i&#39;), (10, &#39;j&#39;), (11, &#39;k&#39;), (12, &#39;l&#39;), (13, &#39;m&#39;), (14, &#39;n&#39;), (15, &#39;o&#39;), (16, &#39;p&#39;), (17, &#39;q&#39;), (18, &#39;r&#39;), (19, &#39;s&#39;), (20, &#39;t&#39;), (21, &#39;u&#39;), (22, &#39;v&#39;), (23, &#39;w&#39;), (24, &#39;x&#39;), (25, &#39;y&#39;), (26, &#39;z&#39;)] . import IPython.display as ipd import numpy as np import itertools . import itertools def ascii_wav(times=3): wave = &quot;¬∞¬∫¬§√∏,¬∏¬∏,√∏¬§¬∫¬∞`&quot; return &#39;&#39;.join(itertools.repeat(wave, times)) ascii_wav() . &#39;¬∞¬∫¬§√∏,¬∏¬∏,√∏¬§¬∫¬∞`¬∞¬∫¬§√∏,¬∏¬∏,√∏¬§¬∫¬∞`¬∞¬∫¬§√∏,¬∏¬∏,√∏¬§¬∫¬∞`&#39; .",
            "url": "https://www.scottcondron.com/jupyter/optimisation/visualisation/2020/09/06/why-you-should-be-using-python-itertools.html",
            "relUrl": "/jupyter/optimisation/visualisation/2020/09/06/why-you-should-be-using-python-itertools.html",
            "date": " ‚Ä¢ Sep 6, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Software Developer to Machine Learning Research Engineer",
            "content": ". Introduction . If you&#39;re reading this, you&#39;re likely interested to read about my experience transitioning from Software Development to Machine Learning to inform whether it&#39;s something you should consider. I&#39;ll share why I decided to change paths and the steps I took to do so hopefully you will feel empowered to make the move yourself. . TLDR: I did online courses which gave me the confidence to go back to university, after which I landed a ML research engineer job. . Finding the confidence . I had been meaning to learn more about AI. I&#39;d watch amazing products being released which boasted that they were &quot;powered by AI&quot;, but I knew very little about it... other than that it was going to be cause of our species&#39; downfall, of course. . I was a Software Developer for 3 years and now I&#39;m a Geoffrey Hinton clone, with a herd of autonomous bots at my fingertips. In reality, I&#39;m building machine learning based applications for a company called Speech Graphics in Edinburgh. . If you take one thing from this post, it&#39;s that developing the confidence to take steps towards working with and understanding machine learning was the most important part of my experience. At first I thought that it was reserved for PhD graduates and a someone like me would need to wait until we can upload knowledge with a human-brain interface before I could understand it. . My way of building confidence was through doing online courses. I was very privileged that the company I worked for at the time, an amazing NFC startup called Flomio, were willing to let me bill hours watching an online course on machine learning. I followed fast.ai&#39;s &quot;Practical Deep Learning for Coders&quot; and then watched CS231n in my spare time. . After that, although there was a fairly long road ahead, it was night and day. I had the confidence that the jelly in my skull didn&#39;t need any additional compute power to grasp it. . Things that helped . If you already know how to code, you can be up and running training models in a day after watching the first lecture of fast.ai. Fast.ai&#39;s &quot;top down approach&quot; really helps motivate continued learning by showing you what&#39;s possible. Having a software developer background really made things easier, you can gradually dive deeper into the different concepts, as you would with a new library or API. . Learning to use a language and a library at the same time can be a pain... first learn the language, then learn the libraries/APIs that are written with it. In my experience, this is true for machine learning too... once I had learned python, picking up fastai and PyTorch was much easier. . Once I had a reasonable grasp of fastai and PyTorch, I looked around for university courses that might help me transition into a machine learning. Although it would‚Äôve been nice to make the transition completely independently outside of institutions, I felt I would benefit from the structure of it and having the degree would also help my job search. . This is by no means a &quot;you need a degree&quot; statement, the most valuable lessons I&#39;ve learned has been from self-guided study online. Taking the risk financially was the hardest consideration for me. My only advice for this is to try and save as much as you can, and look for funding / scholarships where available. . . Note: Tech is a male dominated industry where women are more than twice as likely to quit as men (41% vs 17%) so being a white male, I benefit from lots of other factors. . Going back to uni . So I in enrolled in Artificial Intelligence with Speech and Multimodal Interaction MSc in Heriot Watt University, Edinburgh, Scotland. The course focused on big data applications, intro to data science, statistics, and one fancy module called Biologically Inspired Computation (see my previous two blog posts about Genetic Algorithm and Particle Swarm Optimisation for examples of that). . You may notice that there wasn&#39;t a large amount of Deep Learning there. Although the fundamentals of neural networks were thought and we had to build a neural net from scratch, the online courses I did were a lot more practically useful than what I learned in university, especially fast.ai. . Having had experience programming professionally and having learned many fundamentals from the different online courses, my university experience went a lot smoother than my undergraduate degree. There was lots of late nights and pretty much every weekend was spent doing assignments during the day, but honestly, I enjoyed the sense of purpose that pursuing the degree gave me. . . Note: If you do decide to go the university route, use ANKI (spaced repetition) to study for exams. It is the closest I&#8217;ve been to being able to get to upload facts into my jelly brain. . The Job Search . I added alerts for &quot;Machine Learning&quot; in Edinburgh on the LinkedIn job search feature and spammed my CV wherever matched. If you want to see the CV I send, DM me and I&#39;ll be happy to share. I focused my search on smaller tech companies but I would take any interview offers I received. . Most of the job applications were similar to the Software Developer interview process I had been through before. The main difference was questions would focus on machine learning concepts and the take home would be some data related task, e.g. building a classifier with the given data. . For these take-home tests, I used fastai. This was great for getting quick results but be sure you understand what&#39;s going on behind the scenes because every interview asked about them. . I did 4 interviews with companies in Edinburgh and was offered 4 jobs. I really couldn&#39;t have even imagined that result. There is such demand for data-science / machine learning skills that I had much better job application / interview results that I had prior to all this. This was in the relatively small city of Edinburgh so I imagine opportunities are even greater in bigger cities. . This may sound like it was all roses but financial decisions aside, university was tough and it&#39;s a bit of a grind staying with online course. . Conclusion . In conclusion, I did a few online courses which gave me the confidence to go back to university, upon completion I interviewed for a few companies and settled on the one in which I thought I could learn the most. The whole process was one and a half years from start to finish. I made the decision to join Speech Graphics because machine learning is core to their product and they have a dedicated ML team so I knew I would be in a good position to learn a lot. . To make this whole thing possible, there were many helpful people around me at all points throughout my transition. Between my girlfriend Kerri, my parents to my friends in uni and my dissertaion supervisor, I know its a cliche but I really wouldn&#39;t have been able to do it without each of them being so kind and helpful. . I personally love reading about these kind of stories and finding out about peoples experiences doing something I am considering. Did you get any value from reading this article? If so (or if not), feel free to share it, and you‚Äôre also more than welcome to contact me (via Twitter) if you have any questions, comments, or feedback. . I hope my story has given you an insight into my perspective about switching paths. . Thanks for reading! :rocket: . Follow @_ScottCondron .",
            "url": "https://www.scottcondron.com/deep%20learning/ai/software%20development/2020/09/05/sd-to-ml.html",
            "relUrl": "/deep%20learning/ai/software%20development/2020/09/05/sd-to-ml.html",
            "date": " ‚Ä¢ Sep 5, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Thebe Github Pages",
            "content": "Activate . print(&quot;HellSSo!&quot;) . Why are we here? . I&#39;m hoping it&#39;s to read about Swarm Intelligence! I&#39;m also hoping you&#39;re interested to read about the interactive dashboard side of things too so we can play with it at the end. . If that sounds like too much and you just want to play with it now, you can use it on PyViz examples here: https://particle-swarms.pyviz.demo.anaconda.com . We&#39;re going to build the dashboard using some of Anacondas&#39;s HoloViz tools (Holoviews, Panel and Bokeh) to get the result from the tweet below. . New blog post! ü•≥üï∫Interactive Particle Swarm Optimisation Dashboard from Scratch in Python. Click to set a target and see the particles flock towards it!Uses @HoloViews, @Panel_org and @bokeh for interaction. https://t.co/cCZNwonU3P pic.twitter.com/6xxcAsg1GA . &mdash; Scott Condron (@_ScottCondron) August 12, 2020 . Finding the &quot;just right&quot; Goldilocks Zone using Swarm Intelligence . Say you&#39;re building a house and you want to maximise the number of rooms you can fit in your plot of land, maybe saying that all rooms have to be a certain size or bigger. That&#39;s the kind of thing that optimisation algorithms are useful for. . Optimisation methods like Particle Swarm Optimisation are used when you want to find the best/optimum for some system / problem. You could just try every possible input but that might take a while so smarter people than me have invented better ways. . &#160;No death . This is going to be pretty similar to my Genetic Algorithm blog post except this time there will be a lot less death. You won‚Äôt necessarily need to have read that blog post but I will be referring back to it once or twice so you may want to go back and read that first. . Make it interactive because . Let&#39;s build a dashboard in which you can control parameters of Particle Swarm Optimisation, click a target and see the little dots flock towards it. Like an interactive, 2D version of this plot on Wikipedia. . . Swarm Intelligence . &#160;Wait, why no death? . Genetic algorithm is based on genetic evolution where for each generation there is survival-of-the-fittest-style well... death. In the case of Particle Swarm Optimisation, there is the same population throughout because we want them to remember where they were when they were at their fittest. Like looking back at yourself on your wedding day or after a health kick. Each particles position is a potential solution to your problem so they&#39;re all trying to find the best position together. :heart_eyes: . Adding velocity to the mix . In the case of Genetic Algorithm each member of the population was just a few numbers (their X and Y position), the parameters that you‚Äôre trying to optimise. In this case each particle will not just have a X and Y position, they also have a velocity. We also need a way to know how to improve the particles in our swarm... . &#160;Closer (smaller distance) is better . The same as with Genetic Algorithm, we&#39;ll need to find the fittest member of the population using euclidean distance / mean squared error (which particle is closest to the target). . #collapse-hide def mean_squared_error(y_true, y_pred): return ((y_true - y_pred)**2).mean(axis=0) target_x, target_y = 0,0 def problem(soln): global target_x #using globals so we can link this to the click event later global target_y return mean_squared_error(soln, [target_x, target_y]) def assess_fitness(individual, problem): &quot;Determines the fitness of an individual using the given problem&quot; return problem(individual) . . Nostalgic by design . Each member is going to keep track of their fittest position, this can help them if they explore a worse direction, or want to tell other particles (but we&#39;ll get to that later). They also keep an ID so that we can colour them across iterations. . A portrait of a particle . The big red blob is one particle which has an X and Y position, a velocity and is constantly reminiscing about it&#39;s fittest position. . . Here&#39;s that in code (before we add any of the update logic). . #collapse-hide import numpy as np import pandas as pd import random from holoviews import opts, dim import holoviews as hv import panel as pn from holoviews.streams import Stream hv.extension(&#39;bokeh&#39;, logo=False) . . #collapse-show class Particle: def __init__(self, problem, velocity, position, index): self.problem = problem self.velocity = velocity self.position = position self.fittest_position = position self.id = index . . Create a &quot;swarm&quot; of them . For each particle, we want their position and velocity. . #collapse-show swarm_size = 50 vector_length = 2 # x &amp; y swarm = [Particle(problem, np.random.uniform(-2, 2, vector_length), np.random.rand(vector_length), i) for i, x in enumerate(range(swarm_size))] . . We also convert their velocity into angle and magnitude for the little arrows in the visualisation. Here&#39;s what our swarm looks like: . #collapse-hide def to_angle(vector): x = vector[0] y = vector[1] mag = np.sqrt(x**2 + y**2) angle = (np.pi/2.) - np.arctan2(x/mag, y/mag) return mag, angle def get_vectorfield_data(swarm): &#39;&#39;&#39;Returns (xs, ys, angles, mags, ids)&#39;&#39;&#39; xs, ys, angles, mags, ids = [], [], [], [], [] for particle in swarm: xs.append(particle.position[0]) ys.append(particle.position[1]) mag, angle = to_angle(particle.velocity) mags.append(mag) angles.append(angle) ids.append(particle.id) return xs, ys, angles, mags, ids vect_data = get_vectorfield_data(swarm) vectorfield = hv.VectorField(vect_data, vdims=[&#39;Angle&#39;, &#39;Magnitude&#39;, &#39;Index&#39;]) #¬†[x, y, id] for all particles particles = [np.array([vect_data[0], vect_data[1], vect_data[4]]) for i, particle in enumerate(swarm)] points = hv.Points(particles, vdims=[&#39;Index&#39;]) layout = vectorfield * points layout.opts( opts.VectorField(color=&#39;Index&#39;, cmap=&#39;tab20c&#39;, magnitude=dim(&#39;Magnitude&#39;).norm()*10, pivot=&#39;tail&#39;), opts.Points(color=&#39;Index&#39;, cmap=&#39;tab20c&#39;, size=5) ) pn.Column(layout.opts(width=500, height=500)) . . . . Note: We initialised the particles with a velocity for visualising but we&#8217;ll initialise them with zero velocity when it comes to actually optimising. . Updating . Okay so we have a population of particles, each with a position, velocity and fittest position but how can we update this population to find our optimum spot. . Each particle could just move in the direction that they think the optimum spot is. But if they overshoot it or get lost, thankfully they remember their best position so they can use that a little bit too. . Particles&#39; social lives . Seems pretty inefficient for a bunch of these particles to all be trying the same thing without sharing any information with each other. In PSO, they can get &quot;fittest position&quot; from some other members of the population when they‚Äôre updating (called the social component). . They choose a few other particles and say ‚Äúhey I‚Äôm looking for this red marker, any chance you‚Äôve seen it? ‚Äú and the other particles reply ‚ÄúNo but here is where I was when I was closest to it.‚Äú. Thrilling conversations. . . Note: Intesting side note, PSO was introduced by James Kennedy and Russell Eberhart in 1995 after they discovered its optimisation properties while trying to build a social simulator. . Too much social interaction . A quick way to get stuck with a bad solution to a complex problem is to only listen to one suggestion and following that. This is what happens in particle swarm optimisation when all particles communicate to all of the particles during their update step (called the global component). . Update code . Here&#39;s the code for the Particle to update itself at each iteration. . #collapse-show def update(self, fittest_informant, global_fittest, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step): &quot;&quot;&quot; Updates the velocity and position of the particle using the PSO update algorithm&quot;&quot;&quot; self.position += self.velocity * scale_update_step cognitive = random.uniform(0, follow_personal_best) social = random.uniform(0, follow_social_best) glob = random.uniform(0, follow_global_best) self.velocity = (follow_current * self.velocity + cognitive * (self.fittest_position - self.position) + social * (fittest_informant.fittest_position - self.position) + glob * (global_fittest.fittest_position - self.position)) current_fitness = self.assess_fitness() if (current_fitness &lt; self.previous_fitness and self.previous_fitness is not None): self.fittest_position = self.position self.previous_fitness = current_fitness . . . Note: We are using a variant of the PSO algorithm introduced in 1995, with a social component as well as global. Also, we sample uniformly from 0 and our given update parameter before updating each part of the equation. . There are various values used to determine how to update the current velocity (as described above). . follow_current is how much to use the particles current velocity. | cognitive is how much to use the particles personal best fittest position. | social is how much to use it&#39;s the fittest position of a smaller subset of the population. | glob (global) is how much to use the fittest position of the fittest particle in the population. | . These are applied to the difference between the particles current position and a &quot;fit&quot; other position (either it&#39;s own fittest position or another particle&#39;s fittest position). . Particle Class . Here is the Particle class with the update and assess_fitness methods added in. . #collapse-hide class Particle: &quot;&quot;&quot; An Particle used in PSO. Attributes - problem : function to minimise velocity : nparray The current velocity of the particle position : nparray The current position of the particle, used as the solution for the problem given id : int The unique id of the particle Public Methods - assess_fitness() Determines the fitness of the particle using the given problem update(fittest_informant, global_fittest, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) Updates the velocity and position of the particle using the PSO update algorithm &quot;&quot;&quot; def __init__(self, problem, velocity, position, index): self.velocity = velocity self.position = position self.fittest_position = position self.problem = problem self.id = index self.previous_fitness = 1e7 def assess_fitness(self): &quot;&quot;&quot;Determines the fitness of the particle using the given problem&quot;&quot;&quot; return assess_fitness(self.position, self.problem) def update(self, fittest_informant, global_fittest, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step): &quot;&quot;&quot; Updates the velocity and position of the particle using the PSO update algorithm&quot;&quot;&quot; self.position += self.velocity * scale_update_step cognitive = random.uniform(0, follow_personal_best) social = random.uniform(0, follow_social_best) glob = random.uniform(0, follow_global_best) self.velocity = (follow_current * self.velocity + cognitive * (self.fittest_position - self.position) + social * (fittest_informant.fittest_position - self.position) + glob * (global_fittest.fittest_position - self.position)) current_fitness = self.assess_fitness() if (current_fitness &lt; self.previous_fitness): self.fittest_position = self.position self.previous_fitness = current_fitness . . Find the fittest Particle in the swarm . We use this find_current_best method to keep track of our current fittest Particle, and to find the best among a selected few &quot;informant&quot; Particles for the social component. . #collapse-show def find_current_best(swarm, problem): &quot;&quot;&quot;Evaluates a given swarm and returns the fittest particle based on their best previous position This can be sped up to only loop over swarm once, but because this is a tutorial, 3 lines is nicer. &quot;&quot;&quot; fitnesses = [assess_fitness(x.fittest_position, problem) for x in swarm] best_value = min(fitnesses) best_index = fitnesses.index(best_value) return swarm[best_index] . . PSO Class . This is just a wrapper which updates all the particles and keeps track of the current fittest. . . Note: One thing to note is that we randomly sample the swarm to get the &quot;informants&quot; for the social update in each particle. There are many different topologies that can be chosen for this part of the algorithm, but we&#8217;re keeping it simple here. . #collapse-hide class PSO: &quot;&quot;&quot; An implementation of Particle Swarm Optimisation, pioneered by Kennedy, Eberhart and Shi. The swarm consists of Particles with 2 fixed length vectors; velocity and position. Position is initialised with a uniform distribution between 0 and 1. Velocity is initialised with zeros. Each particle has a given number of informants which are randomly chosen at each iteration. Attributes - swarm_size : int The size of the swarm vector_length : int The dimensions of the problem, should be the same used when creating the problem object num_informants: int The number of informants used for social component in particle velocity update Public Methods - improve(follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) Update each particle in the swarm and updates the global fitness update_swarm(follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) Updates each particle, randomly choosing informants for each particle&#39;s update. update_global_fittest() Updates the `globale_fittest` variable to be the current fittest Particle in the swarm. &quot;&quot;&quot; def __init__(self, problem, swarm_size, vector_length, num_informants=2): self.swarm_size = swarm_size self.num_informants = num_informants self.problem = problem self.swarm = [Particle(self.problem, np.zeros(vector_length), np.random.rand(vector_length), i) for i, x in enumerate(range(swarm_size))] self.global_fittest = np.random.choice(self.swarm, 1)[0] def update_swarm(self, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step): &quot;&quot;&quot;Update each particle in the swarm&quot;&quot;&quot; for particle in self.swarm: informants = np.random.choice(self.swarm, self.num_informants) if particle not in informants: np.append(informants, particle) fittest_informant = find_current_best(informants, self.problem) particle.update(fittest_informant, self.global_fittest, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) def update_global_fittest(self): fittest = find_current_best(self.swarm, self.problem) global_fittest_fitness = self.global_fittest.assess_fitness() if (fittest.assess_fitness() &lt; global_fittest_fitness): self.global_fittest = fittest def improve(self, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step): &quot;&quot;&quot;Improves the population for one iteration.&quot;&quot;&quot; self.update_swarm(follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) self.update_global_fittest() size = 25 vector_length = 2 num_informants = 2 pso = PSO(problem, size, vector_length) . . &#160;Interaction . We&#39;re using Panel (a library from Anaconda) for the sliders and buttons. Because there are a lot of settings for PSO, we&#39;ll leave a escape hatch for people in the form of a reset_button which will set the sliders to their default. . Sliders and defaults . #collapse-hide default_pop_size = 25 default_time = 3 default_num_informants = 6 population_size_slider = pn.widgets.IntSlider(name=&#39;Population Size&#39;, start=10, end=50, value=default_pop_size) time_slider = pn.widgets.IntSlider(name=&#39;Time Evolving (s)&#39;, start=0, end=15, value=default_time) num_informants_slider = pn.widgets.IntSlider(name=&#39;Number of Informants&#39;, start=0, end=20, value=default_num_informants) default_current = 0.7 default_personal_best = 2.0 default_social_best = 0.9 default_global_best = 0.0 default_scale_update_step = 0.7 follow_current_slider = pn.widgets.FloatSlider(name=&#39;Follow Current&#39;, start=0.0, end=5, value=default_current) follow_personal_best_slider = pn.widgets.FloatSlider(name=&#39;Follow Personal Best&#39;, start=0, end=5, value=default_personal_best) follow_social_best_slider = pn.widgets.FloatSlider(name=&#39;Follow Social Best&#39;, start=0.0, end=5, value=default_social_best) follow_global_best_slider = pn.widgets.FloatSlider(name=&#39;Follow Global Best&#39;, start=0.0, end=1, value=default_global_best) scale_update_step_slider = pn.widgets.FloatSlider(name=&#39;Scale Update Step&#39;, start=0.0, end=1, value=0.7) reset_params_button = pn.widgets.Button(name=&#39;Reset Parameters&#39;, width=50) def reset_event(event): global default_current global default_personal_best global default_social_best global default_global_best global default_scale_update_step global default_pop_size global default_time global default_num_informants follow_current_slider.value, follow_personal_best_slider.value = default_current, default_personal_best follow_social_best_slider.value, follow_global_best_slider.value = default_social_best, default_global_best scale_update_step_slider.value, population_size_slider.value = default_scale_update_step, default_pop_size time_slider.value, num_informants_slider.value = default_time, default_num_informants reset_params_button.on_click(reset_event) . . Set the Target . For the &quot;click to set target&quot; interaction, we&#39;ll use a Holoviews DynamicMap. It sounds complicated but put simply, it links a stream with a callback function. In this case the stream we&#39;re using is a hv.stream.SingleTap, which will trigger the tap_event callback function with the x and y position of the tap when a tap happens. A hv.Points object is returned which can be displayed later. . #collapse-show def tap_event(x,y): global target_x global target_y if x is not None: target_x, target_y = x,y return hv.Points((x,y,1), label=&#39;Target&#39;).opts(color=&#39;r&#39;, marker=&#39;^&#39;, size=15) target_x, target_y = 0.5, 0.5 tap_stream = hv.streams.SingleTap(transient=True, x=target_x, y=target_y) target_tap = hv.DynamicMap(tap_event, streams=[tap_stream]) . . Create button events . Now for the best part, animating the Particles. This time our callback will return our swarm visualised using hv.Points for the particle points, hv.VectorField for the velocity arrows, and hv.Points to circle the fittest particle. . We&#39;re going to use a Holoviews DynamicMap again. This time, our stream that we link to the callback is one with no parameters so we can trigger it with our buttons. run_button creates a new population and uses DynamicMap&#39;s periodic method to keep updating it for a given period of time (set with a slider from above). If there&#39;s anything there you&#39;d like explained more, feel free to reach out to me on Twitter. . #collapse-show def update(): pso.improve(follow_current_slider.value, follow_personal_best_slider.value, follow_social_best_slider.value, follow_global_best_slider.value, scale_update_step_slider.value) vect_data = get_vectorfield_data(pso.swarm) vectorfield = hv.VectorField(vect_data, vdims=[&#39;Angle&#39;, &#39;Magnitude&#39;, &#39;Index&#39;]) particles = [np.array([vect_data[0], vect_data[1], vect_data[4]]) for i, particle in enumerate(swarm)] scatter = hv.Points(particles, vdims=[&#39;Index&#39;], group=&#39;Particles&#39;) fittest = hv.Points((pso.global_fittest.fittest_position[0], pso.global_fittest.fittest_position[1],1), label=&#39;Current Fittest&#39;) layout = vectorfield * scatter * fittest layout.opts( opts.Points(color=&#39;b&#39;, fill_alpha=0.1, line_width=1, size=10), opts.VectorField(color=&#39;Index&#39;, cmap=&#39;tab20c&#39;, magnitude=dim(&#39;Magnitude&#39;).norm()*10, pivot=&#39;tail&#39;), opts.Points(&#39;Particles&#39;, color=&#39;Index&#39;, cmap=&#39;tab20c&#39;, size=5, xlim=(0,1), ylim=(0,1)) ) return layout particles = hv.DynamicMap(update, streams=[Stream.define(&#39;Next&#39;)()]) run_button = pn.widgets.Button(name=&#39; u25b6 Begin Improving&#39;, width=50) def b(event): global pso size = population_size_slider.value vector_length = 2 num_informants = num_informants_slider.value pso_fitnesses = [] pso = PSO(problem, size, vector_length, num_informants) particles.periodic(0.005, timeout=time_slider.value) run_button.on_click(b) . . New Population Button . We&#39;ll also add a button which can step through the update process or reset the population. We do this by hooking up other buttons to the particles.streams DynamicMap and passing it to hv.streams.Stream.trigger. . #collapse-show def new_pop_event(event): global pso size = population_size_slider.value num_informants = num_informants_slider.value pso = PSO(problem, size, vector_length=2, num_informants=num_informants) hv.streams.Stream.trigger(particles.streams) new_pop_button = pn.widgets.Button(name=&#39;New Population&#39;, width=50) new_pop_button.on_click(new_pop_event) def next_gen_event(event): hv.streams.Stream.trigger(particles.streams) next_generation_button = pn.widgets.Button(name=&#39;Next Generation&#39;, width=50) next_generation_button.on_click(next_gen_event) . . Layout everything together . #collapse-show instructions = pn.pane.Markdown(&#39;&#39;&#39; # Particle Swarm Optimisation Dashboard ## Instructions: 1. **Click on the plot to place the target.** 2. Click &#39; u25b6 Begin Improving&#39; button to begin improving for the time on the Time Evolving slider. 3. Experiment with the sliders &#39;&#39;&#39;) dashboard = pn.Column(instructions, pn.Row((particles*target_tap).opts(width=600, height=600), pn.Column( pn.Row(run_button, pn.Spacer(width=50), new_pop_button), next_generation_button, time_slider, num_informants_slider, population_size_slider, follow_current_slider, follow_personal_best_slider, follow_social_best_slider, follow_global_best_slider, scale_update_step_slider, reset_params_button))) dashboard . . Here&#39;s a gif of the final result! Click to set a target, set the parameters with the sliders and click the &#39;Begin Improving&#39; button to see the particles swarm! . . Conclusion . Particle Swarm Optimisation is a really intesting algorithm which was built while trying to build a simiplified model of social interactions. The original aim was to create an algorithm in which the particles would behave like flocking birds. Here&#39;s a link if you&#39;d like to read the original paper. . We&#39;ve built PSO from the ground up and have seen how Swarm Intelligence emerges! . We&#39;ve also looked at Anaconda&#39;s HoloViz tools (HoloViews, Panel and Bokeh). Using these we built an interactive dashboard which shows all the particles updating! . I personally love learning about these kind of algorithms and finding ways to interact with them visually. I&#39;d love to hear from you. What do you think about these nature-inspired algorithms? Did you learn a bit about creating interactive visualisations in Python by reading this article? . If so, feel free to share it, and you‚Äôre also more than welcome to contact me (via Twitter) if you have any questions, comments, or feedback. . And finally, here&#39;s the dashboard deployed on PyViz examples: https://particle-swarms.pyviz.demo.anaconda.com . Thanks a lot to the team at Anaconda for their great tools and for deploying this :heart:! . Thanks for reading! :rocket: . Follow @_ScottCondron .",
            "url": "https://www.scottcondron.com/jupyter/optimisation/visualisation/2020/08/02/thebe-github-pages-jekyll.html",
            "relUrl": "/jupyter/optimisation/visualisation/2020/08/02/thebe-github-pages-jekyll.html",
            "date": " ‚Ä¢ Aug 2, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Interactive Particle Swarm Optimisation Dashboard from Scratch in Python",
            "content": "Why are we here? . I&#39;m hoping it&#39;s to read about Swarm Intelligence! I&#39;m also hoping you&#39;re interested to read about the interactive dashboard side of things too so we can play with it at the end. . If that sounds like too much and you just want to play with it now, you can use it on PyViz examples here: https://particle-swarms.pyviz.demo.anaconda.com . We&#39;re going to build the dashboard using some of Anacondas&#39;s HoloViz tools (Holoviews, Panel and Bokeh) to get the result from the tweet below. . New blog post! ü•≥üï∫Interactive Particle Swarm Optimisation Dashboard from Scratch in Python. Click to set a target and see the particles flock towards it!Uses @HoloViews, @Panel_org and @bokeh for interaction. https://t.co/cCZNwonU3P pic.twitter.com/6xxcAsg1GA . &mdash; Scott Condron (@_ScottCondron) August 12, 2020 . Finding the &quot;just right&quot; Goldilocks Zone using Swarm Intelligence . Say you&#39;re building a house and you want to maximise the number of rooms you can fit in your plot of land, maybe saying that all rooms have to be a certain size or bigger. That&#39;s the kind of thing that optimisation algorithms are useful for. . Optimisation methods like Particle Swarm Optimisation are used when you want to find the best/optimum for some system / problem. You could just try every possible input but that might take a while so smarter people than me have invented better ways. . &#160;No death . This is going to be pretty similar to my Genetic Algorithm blog post except this time there will be a lot less death. You won‚Äôt necessarily need to have read that blog post but I will be referring back to it once or twice so you may want to go back and read that first. . Make it interactive because . Let&#39;s build a dashboard in which you can control parameters of Particle Swarm Optimisation, click a target and see the little dots flock towards it. Like an interactive, 2D version of this plot on Wikipedia. . . Swarm Intelligence . &#160;Wait, why no death? . Genetic algorithm is based on genetic evolution where for each generation there is survival-of-the-fittest-style well... death. In the case of Particle Swarm Optimisation, there is the same population throughout because we want them to remember where they were when they were at their fittest. Like looking back at yourself on your wedding day or after a health kick. Each particles position is a potential solution to your problem so they&#39;re all trying to find the best position together. :heart_eyes: . Adding velocity to the mix . In the case of Genetic Algorithm each member of the population was just a few numbers (their X and Y position), the parameters that you‚Äôre trying to optimise. In this case each particle will not just have a X and Y position, they also have a velocity. We also need a way to know how to improve the particles in our swarm... . &#160;Closer (smaller distance) is better . The same as with Genetic Algorithm, we&#39;ll need to find the fittest member of the population using euclidean distance / mean squared error (which particle is closest to the target). . #collapse-hide def mean_squared_error(y_true, y_pred): return ((y_true - y_pred)**2).mean(axis=0) target_x, target_y = 0,0 def problem(soln): global target_x #using globals so we can link this to the click event later global target_y return mean_squared_error(soln, [target_x, target_y]) def assess_fitness(individual, problem): &quot;Determines the fitness of an individual using the given problem&quot; return problem(individual) . . Nostalgic by design . Each member is going to keep track of their fittest position, this can help them if they explore a worse direction, or want to tell other particles (but we&#39;ll get to that later). They also keep an ID so that we can colour them across iterations. . A portrait of a particle . The big red blob is one particle which has an X and Y position, a velocity and is constantly reminiscing about it&#39;s fittest position. . . Here&#39;s that in code (before we add any of the update logic). . #collapse-hide import numpy as np import pandas as pd import random from holoviews import opts, dim import holoviews as hv import panel as pn from holoviews.streams import Stream hv.extension(&#39;bokeh&#39;, logo=False) . . #collapse-show class Particle: def __init__(self, problem, velocity, position, index): self.problem = problem self.velocity = velocity self.position = position self.fittest_position = position self.id = index . . Create a &quot;swarm&quot; of them . For each particle, we want their position and velocity. . #collapse-show swarm_size = 50 vector_length = 2 # x &amp; y swarm = [Particle(problem, np.random.uniform(-2, 2, vector_length), np.random.rand(vector_length), i) for i, x in enumerate(range(swarm_size))] . . We also convert their velocity into angle and magnitude for the little arrows in the visualisation. Here&#39;s what our swarm looks like: . #collapse-hide def to_angle(vector): x = vector[0] y = vector[1] mag = np.sqrt(x**2 + y**2) angle = (np.pi/2.) - np.arctan2(x/mag, y/mag) return mag, angle def get_vectorfield_data(swarm): &#39;&#39;&#39;Returns (xs, ys, angles, mags, ids)&#39;&#39;&#39; xs, ys, angles, mags, ids = [], [], [], [], [] for particle in swarm: xs.append(particle.position[0]) ys.append(particle.position[1]) mag, angle = to_angle(particle.velocity) mags.append(mag) angles.append(angle) ids.append(particle.id) return xs, ys, angles, mags, ids vect_data = get_vectorfield_data(swarm) vectorfield = hv.VectorField(vect_data, vdims=[&#39;Angle&#39;, &#39;Magnitude&#39;, &#39;Index&#39;]) #¬†[x, y, id] for all particles particles = [np.array([vect_data[0], vect_data[1], vect_data[4]]) for i, particle in enumerate(swarm)] points = hv.Points(particles, vdims=[&#39;Index&#39;]) layout = vectorfield * points layout.opts( opts.VectorField(color=&#39;Index&#39;, cmap=&#39;tab20c&#39;, magnitude=dim(&#39;Magnitude&#39;).norm()*10, pivot=&#39;tail&#39;), opts.Points(color=&#39;Index&#39;, cmap=&#39;tab20c&#39;, size=5) ) pn.Column(layout.opts(width=500, height=500)) . . . . Note: We initialised the particles with a velocity for visualising but we&#8217;ll initialise them with zero velocity when it comes to actually optimising. . Updating . Okay so we have a population of particles, each with a position, velocity and fittest position but how can we update this population to find our optimum spot. . Each particle could just move in the direction that they think the optimum spot is. But if they overshoot it or get lost, thankfully they remember their best position so they can use that a little bit too. . Particles&#39; social lives . Seems pretty inefficient for a bunch of these particles to all be trying the same thing without sharing any information with each other. In PSO, they can get &quot;fittest position&quot; from some other members of the population when they‚Äôre updating (called the social component). . They choose a few other particles and say ‚Äúhey I‚Äôm looking for this red marker, any chance you‚Äôve seen it? ‚Äú and the other particles reply ‚ÄúNo but here is where I was when I was closest to it.‚Äú. Thrilling conversations. . . Note: Intesting side note, PSO was introduced by James Kennedy and Russell Eberhart in 1995 after they discovered its optimisation properties while trying to build a social simulator. . Too much social interaction . A quick way to get stuck with a bad solution to a complex problem is to only listen to one suggestion and following that. This is what happens in particle swarm optimisation when all particles communicate to all of the particles during their update step (called the global component). . Update code . Here&#39;s the code for the Particle to update itself at each iteration. . #collapse-show def update(self, fittest_informant, global_fittest, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step): &quot;&quot;&quot; Updates the velocity and position of the particle using the PSO update algorithm&quot;&quot;&quot; self.position += self.velocity * scale_update_step cognitive = random.uniform(0, follow_personal_best) social = random.uniform(0, follow_social_best) glob = random.uniform(0, follow_global_best) self.velocity = (follow_current * self.velocity + cognitive * (self.fittest_position - self.position) + social * (fittest_informant.fittest_position - self.position) + glob * (global_fittest.fittest_position - self.position)) current_fitness = self.assess_fitness() if (current_fitness &lt; self.previous_fitness and self.previous_fitness is not None): self.fittest_position = self.position self.previous_fitness = current_fitness . . . Note: We are using a variant of the PSO algorithm introduced in 1995, with a social component as well as global. Also, we sample uniformly from 0 and our given update parameter before updating each part of the equation. . There are various values used to determine how to update the current velocity (as described above). . follow_current is how much to use the particles current velocity. | cognitive is how much to use the particles personal best fittest position. | social is how much to use it&#39;s the fittest position of a smaller subset of the population. | glob (global) is how much to use the fittest position of the fittest particle in the population. | . These are applied to the difference between the particles current position and a &quot;fit&quot; other position (either it&#39;s own fittest position or another particle&#39;s fittest position). . Particle Class . Here is the Particle class with the update and assess_fitness methods added in. . #collapse-hide class Particle: &quot;&quot;&quot; An Particle used in PSO. Attributes - problem : function to minimise velocity : nparray The current velocity of the particle position : nparray The current position of the particle, used as the solution for the problem given id : int The unique id of the particle Public Methods - assess_fitness() Determines the fitness of the particle using the given problem update(fittest_informant, global_fittest, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) Updates the velocity and position of the particle using the PSO update algorithm &quot;&quot;&quot; def __init__(self, problem, velocity, position, index): self.velocity = velocity self.position = position self.fittest_position = position self.problem = problem self.id = index self.previous_fitness = 1e7 def assess_fitness(self): &quot;&quot;&quot;Determines the fitness of the particle using the given problem&quot;&quot;&quot; return assess_fitness(self.position, self.problem) def update(self, fittest_informant, global_fittest, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step): &quot;&quot;&quot; Updates the velocity and position of the particle using the PSO update algorithm&quot;&quot;&quot; self.position += self.velocity * scale_update_step cognitive = random.uniform(0, follow_personal_best) social = random.uniform(0, follow_social_best) glob = random.uniform(0, follow_global_best) self.velocity = (follow_current * self.velocity + cognitive * (self.fittest_position - self.position) + social * (fittest_informant.fittest_position - self.position) + glob * (global_fittest.fittest_position - self.position)) current_fitness = self.assess_fitness() if (current_fitness &lt; self.previous_fitness): self.fittest_position = self.position self.previous_fitness = current_fitness . . Find the fittest Particle in the swarm . We use this find_current_best method to keep track of our current fittest Particle, and to find the best among a selected few &quot;informant&quot; Particles for the social component. . #collapse-show def find_current_best(swarm, problem): &quot;&quot;&quot;Evaluates a given swarm and returns the fittest particle based on their best previous position This can be sped up to only loop over swarm once, but because this is a tutorial, 3 lines is nicer. &quot;&quot;&quot; fitnesses = [assess_fitness(x.fittest_position, problem) for x in swarm] best_value = min(fitnesses) best_index = fitnesses.index(best_value) return swarm[best_index] . . PSO Class . This is just a wrapper which updates all the particles and keeps track of the current fittest. . . Note: One thing to note is that we randomly sample the swarm to get the &quot;informants&quot; for the social update in each particle. There are many different topologies that can be chosen for this part of the algorithm, but we&#8217;re keeping it simple here. . #collapse-hide class PSO: &quot;&quot;&quot; An implementation of Particle Swarm Optimisation, pioneered by Kennedy, Eberhart and Shi. The swarm consists of Particles with 2 fixed length vectors; velocity and position. Position is initialised with a uniform distribution between 0 and 1. Velocity is initialised with zeros. Each particle has a given number of informants which are randomly chosen at each iteration. Attributes - swarm_size : int The size of the swarm vector_length : int The dimensions of the problem, should be the same used when creating the problem object num_informants: int The number of informants used for social component in particle velocity update Public Methods - improve(follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) Update each particle in the swarm and updates the global fitness update_swarm(follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) Updates each particle, randomly choosing informants for each particle&#39;s update. update_global_fittest() Updates the `globale_fittest` variable to be the current fittest Particle in the swarm. &quot;&quot;&quot; def __init__(self, problem, swarm_size, vector_length, num_informants=2): self.swarm_size = swarm_size self.num_informants = num_informants self.problem = problem self.swarm = [Particle(self.problem, np.zeros(vector_length), np.random.rand(vector_length), i) for i, x in enumerate(range(swarm_size))] self.global_fittest = np.random.choice(self.swarm, 1)[0] def update_swarm(self, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step): &quot;&quot;&quot;Update each particle in the swarm&quot;&quot;&quot; for particle in self.swarm: informants = np.random.choice(self.swarm, self.num_informants) if particle not in informants: np.append(informants, particle) fittest_informant = find_current_best(informants, self.problem) particle.update(fittest_informant, self.global_fittest, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) def update_global_fittest(self): fittest = find_current_best(self.swarm, self.problem) global_fittest_fitness = self.global_fittest.assess_fitness() if (fittest.assess_fitness() &lt; global_fittest_fitness): self.global_fittest = fittest def improve(self, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step): &quot;&quot;&quot;Improves the population for one iteration.&quot;&quot;&quot; self.update_swarm(follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) self.update_global_fittest() size = 25 vector_length = 2 num_informants = 2 pso = PSO(problem, size, vector_length) . . &#160;Interaction . We&#39;re using Panel (a library from Anaconda) for the sliders and buttons. Because there are a lot of settings for PSO, we&#39;ll leave a escape hatch for people in the form of a reset_button which will set the sliders to their default. . Sliders and defaults . #collapse-hide default_pop_size = 25 default_time = 3 default_num_informants = 6 population_size_slider = pn.widgets.IntSlider(name=&#39;Population Size&#39;, start=10, end=50, value=default_pop_size) time_slider = pn.widgets.IntSlider(name=&#39;Time Evolving (s)&#39;, start=0, end=15, value=default_time) num_informants_slider = pn.widgets.IntSlider(name=&#39;Number of Informants&#39;, start=0, end=20, value=default_num_informants) default_current = 0.7 default_personal_best = 2.0 default_social_best = 0.9 default_global_best = 0.0 default_scale_update_step = 0.7 follow_current_slider = pn.widgets.FloatSlider(name=&#39;Follow Current&#39;, start=0.0, end=5, value=default_current) follow_personal_best_slider = pn.widgets.FloatSlider(name=&#39;Follow Personal Best&#39;, start=0, end=5, value=default_personal_best) follow_social_best_slider = pn.widgets.FloatSlider(name=&#39;Follow Social Best&#39;, start=0.0, end=5, value=default_social_best) follow_global_best_slider = pn.widgets.FloatSlider(name=&#39;Follow Global Best&#39;, start=0.0, end=1, value=default_global_best) scale_update_step_slider = pn.widgets.FloatSlider(name=&#39;Scale Update Step&#39;, start=0.0, end=1, value=0.7) reset_params_button = pn.widgets.Button(name=&#39;Reset Parameters&#39;, width=50) def reset_event(event): global default_current global default_personal_best global default_social_best global default_global_best global default_scale_update_step global default_pop_size global default_time global default_num_informants follow_current_slider.value, follow_personal_best_slider.value = default_current, default_personal_best follow_social_best_slider.value, follow_global_best_slider.value = default_social_best, default_global_best scale_update_step_slider.value, population_size_slider.value = default_scale_update_step, default_pop_size time_slider.value, num_informants_slider.value = default_time, default_num_informants reset_params_button.on_click(reset_event) . . Set the Target . For the &quot;click to set target&quot; interaction, we&#39;ll use a Holoviews DynamicMap. It sounds complicated but put simply, it links a stream with a callback function. In this case the stream we&#39;re using is a hv.stream.SingleTap, which will trigger the tap_event callback function with the x and y position of the tap when a tap happens. A hv.Points object is returned which can be displayed later. . #collapse-show def tap_event(x,y): global target_x global target_y if x is not None: target_x, target_y = x,y return hv.Points((x,y,1), label=&#39;Target&#39;).opts(color=&#39;r&#39;, marker=&#39;^&#39;, size=15) target_x, target_y = 0.5, 0.5 tap_stream = hv.streams.SingleTap(transient=True, x=target_x, y=target_y) target_tap = hv.DynamicMap(tap_event, streams=[tap_stream]) . . Create button events . Now for the best part, animating the Particles. This time our callback will return our swarm visualised using hv.Points for the particle points, hv.VectorField for the velocity arrows, and hv.Points to circle the fittest particle. . We&#39;re going to use a Holoviews DynamicMap again. This time, our stream that we link to the callback is one with no parameters so we can trigger it with our buttons. run_button creates a new population and uses DynamicMap&#39;s periodic method to keep updating it for a given period of time (set with a slider from above). If there&#39;s anything there you&#39;d like explained more, feel free to reach out to me on Twitter. . #collapse-show def update(): pso.improve(follow_current_slider.value, follow_personal_best_slider.value, follow_social_best_slider.value, follow_global_best_slider.value, scale_update_step_slider.value) vect_data = get_vectorfield_data(pso.swarm) vectorfield = hv.VectorField(vect_data, vdims=[&#39;Angle&#39;, &#39;Magnitude&#39;, &#39;Index&#39;]) particles = [np.array([vect_data[0], vect_data[1], vect_data[4]]) for i, particle in enumerate(swarm)] scatter = hv.Points(particles, vdims=[&#39;Index&#39;], group=&#39;Particles&#39;) fittest = hv.Points((pso.global_fittest.fittest_position[0], pso.global_fittest.fittest_position[1],1), label=&#39;Current Fittest&#39;) layout = vectorfield * scatter * fittest layout.opts( opts.Points(color=&#39;b&#39;, fill_alpha=0.1, line_width=1, size=10), opts.VectorField(color=&#39;Index&#39;, cmap=&#39;tab20c&#39;, magnitude=dim(&#39;Magnitude&#39;).norm()*10, pivot=&#39;tail&#39;), opts.Points(&#39;Particles&#39;, color=&#39;Index&#39;, cmap=&#39;tab20c&#39;, size=5, xlim=(0,1), ylim=(0,1)) ) return layout particles = hv.DynamicMap(update, streams=[Stream.define(&#39;Next&#39;)()]) run_button = pn.widgets.Button(name=&#39; u25b6 Begin Improving&#39;, width=50) def b(event): global pso size = population_size_slider.value vector_length = 2 num_informants = num_informants_slider.value pso_fitnesses = [] pso = PSO(problem, size, vector_length, num_informants) particles.periodic(0.005, timeout=time_slider.value) run_button.on_click(b) . . New Population Button . We&#39;ll also add a button which can step through the update process or reset the population. We do this by hooking up other buttons to the particles.streams DynamicMap and passing it to hv.streams.Stream.trigger. . #collapse-show def new_pop_event(event): global pso size = population_size_slider.value num_informants = num_informants_slider.value pso = PSO(problem, size, vector_length=2, num_informants=num_informants) hv.streams.Stream.trigger(particles.streams) new_pop_button = pn.widgets.Button(name=&#39;New Population&#39;, width=50) new_pop_button.on_click(new_pop_event) def next_gen_event(event): hv.streams.Stream.trigger(particles.streams) next_generation_button = pn.widgets.Button(name=&#39;Next Generation&#39;, width=50) next_generation_button.on_click(next_gen_event) . . Layout everything together . #collapse-show instructions = pn.pane.Markdown(&#39;&#39;&#39; # Particle Swarm Optimisation Dashboard ## Instructions: 1. **Click on the plot to place the target.** 2. Click &#39; u25b6 Begin Improving&#39; button to begin improving for the time on the Time Evolving slider. 3. Experiment with the sliders &#39;&#39;&#39;) dashboard = pn.Column(instructions, pn.Row((particles*target_tap).opts(width=600, height=600), pn.Column( pn.Row(run_button, pn.Spacer(width=50), new_pop_button), next_generation_button, time_slider, num_informants_slider, population_size_slider, follow_current_slider, follow_personal_best_slider, follow_social_best_slider, follow_global_best_slider, scale_update_step_slider, reset_params_button))) dashboard . . Here&#39;s a gif of the final result! Click to set a target, set the parameters with the sliders and click the &#39;Begin Improving&#39; button to see the particles swarm! . . Conclusion . Particle Swarm Optimisation is a really intesting algorithm which was built while trying to build a simiplified model of social interactions. The original aim was to create an algorithm in which the particles would behave like flocking birds. Here&#39;s a link if you&#39;d like to read the original paper. . We&#39;ve built PSO from the ground up and have seen how Swarm Intelligence emerges! . We&#39;ve also looked at Anaconda&#39;s HoloViz tools (HoloViews, Panel and Bokeh). Using these we built an interactive dashboard which shows all the particles updating! . I personally love learning about these kind of algorithms and finding ways to interact with them visually. I&#39;d love to hear from you. What do you think about these nature-inspired algorithms? Did you learn a bit about creating interactive visualisations in Python by reading this article? . If so, feel free to share it, and you‚Äôre also more than welcome to contact me (via Twitter) if you have any questions, comments, or feedback. . And finally, here&#39;s the dashboard deployed on PyViz examples: https://particle-swarms.pyviz.demo.anaconda.com . Thanks a lot to the team at Anaconda for their great tools and for deploying this :heart:! . Thanks for reading! :rocket: . Follow @_ScottCondron .",
            "url": "https://www.scottcondron.com/jupyter/optimisation/visualisation/2020/08/02/interactive-particle-swarm-optimisation-from-scratch-in-python.html",
            "relUrl": "/jupyter/optimisation/visualisation/2020/08/02/interactive-particle-swarm-optimisation-from-scratch-in-python.html",
            "date": " ‚Ä¢ Aug 2, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Interactive Genetic Algorithm Dashboard from Scratch in Python",
            "content": "What are we doing? . If you want to interact with the final result first, you can play with it on to PyViz examples here: https://genetic-algorithm.pyviz.demo.anaconda.com/GA . How can you maximise the number of components in a laptop, while having size, weight and price constraints? For questions like these, we often want to reach for optimisation algorithms, and one particularly fun one is Genetic Algorithm. . Genetic Algorithm is cool so I created an interactive Genetic Algorithm dashboard with @HoloViews and @Panel_org.Click to set a target and see the little critters evolve to be closest to it. Each time there is a generational update, the plot changes to show their positions. pic.twitter.com/5K9Ehp7wlo . &mdash; Scott Condron (@_ScottCondron) July 18, 2020 . Our example problem . For the sake of a fun visualisation, let&#39;s say the optimisation is &quot;Wherever I click on the plot is the optimimum spot to find&quot;. We&#39;re going to use a population-based approach, Genetic Algorithm, in which there is a population of individuals (each individual representing a possible solution) which evolve across generations. Each solution is just the individual&#39;s x and y coordinates. . What we want to see . We want to see a kind of &quot;evolution simulator&quot; in which we click a spot on the plot and when we begin evolving, each generation moves closer to the place we clicked. . We need a population . &quot;And God said, Let us make man in our image&quot;. First, let&#39;s create a population. . Imports . #collapse-hide import math import numpy as np import pandas as pd import random from holoviews import opts from matplotlib import pyplot as plt import holoviews as hv import panel as pn from holoviews.streams import Stream hv.extension(&#39;matplotlib&#39;, logo=False) . . Create Population . #collapse-show def create_population(population_size, vector_length): return np.random.rand(population_size, vector_length) population_size = 100 vector_length = 2 current_population = create_population(population_size, vector_length) hv.Scatter(current_population) . . Survival of the fittest . We&#39;re going to need to evolve individuals from our population, so we need some way to check which of the population is the fittest. . &#160;Closer (smaller distance) is better . For the sake of this visualisation, we&#39;re going to place a target on the plot and the &quot;fitness&quot; of a individual is how close they are to the target. We&#39;re going to calculate the distance using the euclidean distance metric. . #collapse-show def mean_squared_error(y_true, y_pred): return ((y_true - y_pred)**2).mean(axis=0) target_x, target_y = 0,0 def problem(soln): global target_x #using globals so we can link this to the click event later global target_y return mean_squared_error(soln, [target_x, target_y]) . . Then we need a way to check, who&#39;s our fittest member of our community . #collapse-show def assess_fitness(individual, problem): &quot;Determines the fitness of an individual using the given problem&quot; return problem(individual) def find_current_best(population, problem): &quot;&quot;&quot;Evaluates a given population and returns the fittest individual. This can be sped up to only loop over popuation once, but because this is a tutorial, 3 lines is nicer. &quot;&quot;&quot; fitnesses = [assess_fitness(x, problem) for x in population] best_value = min(fitnesses) # Lowest is best best_index = fitnesses.index(best_value) return population[best_index] . . aaaand Fight! . Now, we&#39;re going to let these potential solutions fight it out and only let a certain few have offspring. For this we will use &quot;Tournament Selection&quot; which is just grabbing a few individuals and having them compete to the death (the fittest survives!). . What&#39;s nice about this is that you can keep a bit of diversity within the population and it&#39;s not just the best that survive, some lucky unfit individuals might be matched up with worse folk, and so they&#39;ll survive. . #collapse-show def tournament_select_with_replacement(population, tournament_size, problem): &quot;Competes a number of challengers and returns the fittest one&quot; challengers_indexes = np.random.choice(population.shape[0], tournament_size, replace=True) challengers = population[challengers_indexes] return find_current_best(challengers, problem) . . Then once we have done this twice, those two individuals can &quot;mate&quot; and have children... to keep the population the same across generations for simplicity, they&#39;ll have two children. We&#39;ll use Two point Crossover), which is just splitting both parents in three parts and swapping the middle part to form two children. . #collapse-show def crossover(parent_a, parent_b): &quot;Performs two point crossover on two parents&quot; l = parent_a.shape[0] c, d = random.randint(0, l), random.randint(0, l) # Flip if c greater than d if (c &gt; d): d, c = c, d if (c == d): d += 1 temp = np.copy(parent_a) child_a = np.concatenate([parent_a[0:c], parent_b[c:d], parent_a[d:]]) child_b = np.concatenate([parent_b[0:c], temp[c:d], parent_b[d:]]) return child_a, child_b . . . Mutate! . For extra variety across generations, we want to introduce a bit of chaos to the system to produce the Marie Curie of each generation (but also probably our least capable individuals too). This helps find new solutions outside our current population&#39;s capability. So for each individual, there&#39;s a chance that their offspring will mutate (determined by mutation_rate). . #collapse-show def mutate(child, mutation_rate, mutation_scale): &quot;May mutate a child using Gaussian convolution&quot; if mutation_rate &gt;= random.uniform(0, 1): size = child.shape[0] mutation_value = np.random.normal(0, mutation_scale, size) child = child + mutation_value return child . . Here&#39;s the entirety of what happens to the population between generations. To recap: a bunch from the current population are selected at random to compete to reproduce. Two parents then produce two children using a mix of the two parents for both children. Finally, each child has a chance that they will mutate. One we&#39;ve created a new population of the same size as the original population, we have completed one &quot;generation&quot;. . #collapse-show def update_population(current_population, problem, should_mutate, mutation_rate, mutation_scale): &quot;&quot;&quot;Performs one generational update of Genetic Algorithm&quot;&quot;&quot; pop_size = len(current_population) next_population = np.empty((pop_size, 2)) tournament_size=2 for i in range(int(pop_size / 2)): parent_a = tournament_select_with_replacement(current_population, tournament_size, problem) parent_b = tournament_select_with_replacement(current_population, tournament_size, problem) child_a, child_b = crossover(parent_a, parent_b) next_population[i] = mutate(child_a, mutation_rate, mutation_scale) if should_mutate else child_a position_child_b = i + (pop_size / 2) next_population[int(position_child_b)] = mutate(child_b, mutation_rate, mutation_scale) if should_mutate else child_b return next_population . . A little class for saving the state of the evolution . #collapse-show class GeneticAlgorithm(object): def __init__(self, population_size, vector_length, problem): self.problem = problem self.current_population = create_population(population_size, vector_length) self.current_best = find_current_best(self.current_population, self.problem) def next_generation(self, mrate, mscale, should_mutate): self.current_population = update_population(self.current_population, self.problem, should_mutate, mrate, mscale) self.current_best = find_current_best(self.current_population, self.problem) ga = GeneticAlgorithm(population_size, vector_length, problem) . . Interact . The sliders, tap streams, and buttons for our dashboard. This is all using Holoviews and Panel. . Buttons . run_button begins a periodic update of our evolution process when the pn.widgets.Button is clicked. next_generation_button triggers just one generational update. new_pop_button triggers the creation of a new population. . Sliders and Layout . The rest are just pn.widgets.IntSlider or pn.widgets.FloatSlider sliders and markdown for the other bits and bobs. This is then positioned out using pn.Column, pn.Row and pn.Spacer from panel. . #collapse-show hv.extension(&#39;bokeh&#39;, logo=False) def tap_event(x,y): global target_x global target_y if x is not None: target_x, target_y = x,y return hv.Points((x,y,1), label=&#39;Target&#39;).opts(color=&#39;r&#39;, marker=&#39;^&#39;, size=10) target_x, target_y = 10, -10 tap = hv.streams.SingleTap(transient=True, x=target_x, y=target_y) tap_dmap = hv.DynamicMap(tap_event, streams=[tap]) mutate_checkbox = pn.widgets.Checkbox(name=&#39;Mutate&#39;, value=True) niters_slider = pn.widgets.IntSlider(name=&#39;Time Evolving (s)&#39;, start=0, end=50, value=5) mutation_rate_slider = pn.widgets.FloatSlider(name=&#39;Mutation Rate&#39;, start=0.0, end=1.0, value=0.3) mutation_scale_slider = pn.widgets.IntSlider(name=&#39;Mutation Scale&#39;, start=0, end=50, value=1) new_pop_button = pn.widgets.Button(name=&#39;New Population&#39;, width=50) def e(event): global ga population_size = 100 vector_length = 2 ga = GeneticAlgorithm(population_size, vector_length, problem) hv.streams.Stream.trigger(pso_scatter.streams) new_pop_button.on_click(e) next_generation_button = pn.widgets.Button(name=&#39;Next Generation&#39;, width=50) def next_gen_event(event): hv.streams.Stream.trigger(pso_scatter.streams) next_generation_button.on_click(next_gen_event) def update(): ga.next_generation(mutation_rate_slider.value, mutation_scale_slider.value, mutate_checkbox.value) pop_scatter = hv.Scatter(ga.current_population, label=&#39;Population&#39;) best_points = hv.Points((ga.current_best[0], ga.current_best[1], 1), label=&#39;Current Fittest&#39;) merged = pop_scatter * best_points merged.opts( opts.Scatter(color=&#39;b&#39;), opts.Points(color=&#39;c&#39;, size=10) ) return merged pso_scatter = hv.DynamicMap(update, streams=[Stream.define(&#39;Next&#39;)()]) run_button = pn.widgets.Button(name=&#39; u25b6 Begin Evolving&#39;, width=50) def b(event): pso_scatter.periodic(0.1, timeout=niters_slider.value, block=False) run_button.on_click(b) instructions = pn.pane.Markdown(&#39;&#39;&#39; # Genetic Algorithm Dashboard ## Instructions: 1. **Click on the plot to place the target.** 2. Click &#39; u25b6 Begin Evolution&#39; button to begin evolving for the time on the Time Evolving slider. 3. Experiment with the Mutation Rate (the probability of an individual in the next generation mutating) 4. Experiment with the Mutation Scale (the size of the mutation, tip: zoom out using the Wheel Zoom on the right of the plot). &#39;&#39;&#39;) combined_dashboard = pso_scatter*tap_dmap dashboard = pn.Column(instructions, pn.Row(combined_dashboard.opts(width=600, height=600), pn.Column( pn.Row(run_button, pn.Spacer(width=50), new_pop_button), next_generation_button, mutate_checkbox, niters_slider, mutation_rate_slider, mutation_scale_slider))) #¬†dashboard # uncomment this to view the dashboard . . . Play with it yourself! . Here it is deployed on PyViz examples: https://genetic-algorithm.pyviz.demo.anaconda.com/GA. . You can also view and run all the code yourself from here. Thanks for reading. . I personally love learning about these kind of algorithms and finding ways to interact with them visually. What do you think about these nature-inspired algorithms? Did you learn a bit about creating interactive visualisations in Python by reading this article? If so, feel free to share it, and you‚Äôre also more than welcome to contact me (via Twitter) if you have any questions, comments, or feedback. . Thanks for reading! :rocket: . Follow me on Twitter here for more stuff like this. . Follow @_ScottCondron .",
            "url": "https://www.scottcondron.com/jupyter/optimisation/visualisation/2020/07/20/interactive-genetic-algorithm-dashboard-from-scratch-in-python.html",
            "relUrl": "/jupyter/optimisation/visualisation/2020/07/20/interactive-genetic-algorithm-dashboard-from-scratch-in-python.html",
            "date": " ‚Ä¢ Jul 20, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "This blog post was written in a Jupyter Notebook",
            "content": "Why should I care? . I think it&#39;s kind of cool that you can write text beside snippets of code that actually run and automatically have the output of your code display alongside it. . A quick example: . Say I want to describe a function that plots a sine wave at different amplitudes. . First, I would define the function . import matplotlib.pyplot as plt import numpy as np def plot_sin(amplitude=1): &#39;&#39;&#39;Plot a sine wave of a given amplitude&#39;&#39;&#39; time = np.arange(0, 10, 0.1) y = np.sin(time) plt.plot(time, amplitude*y) plt.ylabel(&#39;Amplitude&#39;) plt.xlabel(&#39;Time (s)&#39;) plt.show() . Then, just after defining it, I could call it with different arguments and display the outputs alongside any text. . Sine wave with the default amplitude of 1 . plot_sin() . Sine wave with an amplitude of 20 . plot_sin(amplitude=20) . All of the above was written and ran within a Jupyter Notebook and automatically formatted for this blogpost. I didn&#39;t have to have some scripts lying around to create the images in the post. I didn&#39;t have to save, upload and link to the images. I didn&#39;t have to worry that the code examples wouldn&#39;t run. . You can also paste images as you would expect. . . How is that possible? . It&#39;s a mix and match of a few different tools. . Namely: . Jupyter Notebooks | fast-template | Github Pages | Jekyll | nbdev | . Jupyter Notebooks . I&#39;m imagining most people reading this will know what Jupyter Notebooks are. From their website: . The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. . fast-template . The repo was first created from the fast-template repo from fast.ai&#39;s Jeremy Howard. This is a simplified way to generate a blog and host it using Github Pages. You can write your posts in Markdown Language and when you commit them to your repo, they will be converted to html for your blog using Jekyll. . nbdev . nbdev is a really powerful library which isn&#39;t being used to it&#39;s fullest potential here. It&#39;s a tool to create entire python libraries, a website hosting your documentation and way to automatically run tests... all using Jupyter Notebooks. . But for this project, it&#39;s being used to export output cells and any uploaded attachment from Jupyter Notebooks to markdown using nbdev_detach *.ipynb and nbdev_nb2md to convert notebooks to markdown. It&#39;s also being used to remove metadata from the notebooks during git commits, which helps reducing the change of merge conflicts. That last feature is probably overkill because I don&#39;t think I&#39;ll be doing a lot of merging. . Github Actions . Last but not least, Github Actions runs all of the above during each commit automatically! See here for the config. This is mostly taken from nbdev with a few things changed. . Thanks for reading . If you&#39;d like, you can find this blogs github repo here or follow me on Twitter here . A huge thanks to Jeremy Howard at fastai for making fast-template and nbdev which is doing all of the hard work to bring all these tools together! .",
            "url": "https://www.scottcondron.com/jupyter/blogging/visualisation/2020/01/20/this-blog-post-was-written-in-a-jupyter-notebooks.html",
            "relUrl": "/jupyter/blogging/visualisation/2020/01/20/this-blog-post-was-written-in-a-jupyter-notebooks.html",
            "date": " ‚Ä¢ Jan 20, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Begin creating Deep Learning¬†models.",
            "content": "Following the advice of Julia Evans, I&#39;m going to write about things that I wish I knew a year ago. Machine Learning research sometimes feels like an activity reserved for the intellectually superior, while us mere mortals enjoy their trimmings when they publish and the open-source community implements it. . . You don&#39;t need a&#160;PhD . This myth was completely debunked for me when I took the fast.ai course, Practical Deep Learning for Coders, v3. So my first tip, do it. Also, this post by Rachel Thomas gives some great advice to those thinking about grad school. . If some of the stuff below seems like gibberish, fast.ai is a good place to go. . Tips for people wanting to begin creating / improving deep learning&#160;models. . Find a dataset that interests you. Here&#39;s a good post about where to find it. Try not to get analysis paralysis, just choose one. You&#39;re not married to the dataset you choose, but get to know it. . Here are plenty of resources to learn to visualize and analyze a dataset. . Use Google&#160;Colab . If you want free access to a GPU, here you go. If you want to know why or setting up a GPU is becoming frustrating. . Get 100% accuracy on one instance/batch of your&#160;data . Rather than wasting your time loading all of the data each time you want to check for bugs, create a tiny dataset with just one instance of your dataset and overfit it with a very simple model. . &#160;Get 100% accuracy on around 10% of your&#160;data . Once you can overfit your model on one instance, begin using more of your data and try to overfit it by adding more layers. Don&#39;t use any regularization for the moment (e.g., Dropout, L1/ L2 regularization), this is another sanity preserving tip so you know that your model is learning. . &#160;Add all of your training&#160;data . Once you add all of your data, if training is taking too long, leave it aside as an experiment and continue your work on the 10% of data. If you&#39;re overfitting when you add more layers and all of your data, here&#39;s five steps to reduce overfitting. . . And that&#39;s it for today, those tips are some of the valuable gems that I wish I found out sooner. If have any feedback, here&#39;s me on Twitter. . Thanks for reading .",
            "url": "https://www.scottcondron.com/deep%20learning/ai/2020/01/17/begin-creating-dl-models.html",
            "relUrl": "/deep%20learning/ai/2020/01/17/begin-creating-dl-models.html",
            "date": " ‚Ä¢ Jan 17, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Who I am . I‚Äôm a Machine Learning Engineer from Dublin, Ireland üáÆüá™ and living in Edinburgh, Scotland üè¥Û†ÅßÛ†Å¢Û†Å≥Û†Å£Û†Å¥Û†Åø. I‚Äôm from a family of small business owners. . Why I built this website . The main reason for building this blog was to have an outlet for sharing things I learn or build. I‚Äôm hoping people will enjoy the blog so much that they‚Äôll reach out and I‚Äôll build relationships with like-minded people. . What am I up to . I‚Äôm currently interested in Deep Learning, Python Software Development and Data Visualisation. . I was working as a web/mobile Software Developer for a few years and then went back to University to do an MSc in AI in Heriot Watt University, Edinburgh. Following that, I worked for 2 years as a Research Engineer at Speech Graphics. . I‚Äôm now working as a Machine Learning Engineer at Weights &amp; Biases. . You can follow me on Twitter here. .",
          "url": "https://www.scottcondron.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://www.scottcondron.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
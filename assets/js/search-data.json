{
  
    
        "post0": {
            "title": "Interactive Particle Swarm Optimisation Dashboard from Scratch in Python",
            "content": "Why are we here? . I&#39;m hoping it&#39;s to read about Swarm Intelligence! I&#39;m also hoping you&#39;re interested to read about the interactive dashboard side of things too so we can play with it at the end. . We&#39;re going to build the dashboard using some of Anacondas&#39;s HoloViz tools (Holoviews, Panel and Bokeh) to get the result from the tweet below. . After building an Interactive Genetic Algorithm Dashboard last week (https://t.co/u7fssGvaEP), I thought it would be fun to see Particle Swarm Optimisation (PSO) in action. Click to set a target and watch them fly towards it.All built using @HoloViews, @Panel_org and @bokeh. pic.twitter.com/j5bVHieFUS . &mdash; Scott Condron (@_ScottCondron) July 28, 2020 . Finding the &quot;just right&quot; Goldilocks Zone using Swarm Intelligence . Say you&#39;re building a house and you want to maximise the number of rooms you can fit in your plot of land, maybe saying that all rooms have to be a certain size or bigger. That&#39;s the kind of thing that optimisation algorithms are useful for. . Optimisation methods like Particle Swarm Optimisation are used when you want to find the best/optimum for some system / problem. You could just try every possible input but that might take a while so smarter people than me have invented better ways. . &#160; No death . This is going to be pretty similar to my Genetic Algorithm blog post except this time there will be a lot less death. You won‚Äôt necessarily need to have read that blog post but I will be referring back to it once or twice so you may want to go back and read that first. . Make it interactive because . Let&#39;s build a dashboard in which you can control parameters of Particle Swarm Optimisation, click a target and see the little dots flock towards it. Like an interactive, 2D version of this plot on Wikipedia. . . Swarm Intelligence . &#160;Wait, why no death? . Genetic algorithm is based on genetic evolution where each generation there is survival-of-the-fittest-style well... death. In the case of Particle Swarm Optimisation, there is the same population throughout because we want them to remember where they were when they were at their fittest. Like looking back at yourself on your wedding day or after a health kick. Each particles position is a potential solution to your problem so they&#39;re all trying to find the best position together. :heart_eyes: . Adding velocity to the mix . In the case of Genetic Algorithm each member of the population was just a few numbers (their X and Y position), the parameters that you‚Äôre trying to optimise. In this case each particle will not just have a X and Y position, they also have a velocity. We also need a way to know how to improve the particles in our swarm... . &#160;Closer (smaller distance) is better . The same as with Genetic Algorithm, we&#39;ll need to find the fittest member of the population using euclidean distance / mean squared error (which particle is closest to the target). . #collapse-hide def mean_squared_error(y_true, y_pred): return ((y_true - y_pred)**2).mean(axis=0) target_x, target_y = 0,0 def problem(soln): global target_x #using globals so we can link this to the click event later global target_y return mean_squared_error(soln, [target_x, target_y]) def assess_fitness(individual, problem): &quot;Determines the fitness of an individual using the given problem&quot; return problem(individual) . . Nostalgic by design . Each member is going to keep track of their fittest position, this can help them if they explore a worse direction, or want to tell other particles (but we&#39;ll get to that later). They also keep an ID so that we can colour them across iterations. . A portrait of a particle . The bigger red blob is one particle which has an X and Y position, a velocity and is constantly reminiscing about it&#39;s fittest position. . . Here&#39;s that in code (before we add any of the update logic). . #collapse-hide import numpy as np import pandas as pd import random from holoviews import opts, dim import holoviews as hv import panel as pn from holoviews.streams import Stream hv.extension(&#39;bokeh&#39;, logo=False) . . #collapse-show class Particle: def __init__(self, problem, velocity, position, index): self.problem = problem self.velocity = velocity self.position = position self.fittest_position = position self.id = index . . Create a &quot;swarm&quot; of them . For each particle, we want their position and velocity. We also convert their velocity into angle and magnitude for the little arrows in the visualisation. . #collapse-show swarm_size = 50 swarm = [Particle(problem, np.random.uniform(-2, 2, vector_length), np.random.rand(vector_length), i) for i, x in enumerate(range(swarm_size))] . . Here&#39;s what our swarm looks like: . #collapse-hide def to_angle(vector): x = vector[0] y = vector[1] mag = np.sqrt(x**2 + y**2) angle = (np.pi/2.) - np.arctan2(x/mag, y/mag) return mag, angle def get_vectorfield_data(swarm): &#39;&#39;&#39;Returns (xs, ys, angles, mags, ids)&#39;&#39;&#39; xs, ys, angles, mags, ids = [], [], [], [], [] for particle in swarm: xs.append(particle.position[0]) ys.append(particle.position[1]) mag, angle = to_angle(particle.velocity) mags.append(mag) angles.append(angle) ids.append(particle.id) return xs, ys, angles, mags, ids vect_data = get_vectorfield_data(swarm) vectorfield = hv.VectorField(vect_data, vdims=[&#39;Angle&#39;, &#39;Magnitude&#39;, &#39;Index&#39;]) #¬†[x, y, id] for all particles particles = [np.array([vect_data[0], vect_data[1], vect_data[4]]) for i, particle in enumerate(swarm)] points = hv.Points(particles, vdims=[&#39;Index&#39;]) layout = vectorfield * points layout.opts( opts.VectorField(color=&#39;Index&#39;, cmap=&#39;tab20c&#39;, magnitude=dim(&#39;Magnitude&#39;).norm()*10, pivot=&#39;tail&#39;), opts.Points(color=&#39;Index&#39;, cmap=&#39;tab20c&#39;, size=5) ) pn.Column(layout.opts(width=500, height=500)).servable() . . . Note: Here we initialised the particles with a velocity for visualisationg, we&#8217;ll initialise them with zero velocity when it comes to actually optimising. . Updating . Okay so we have a population of particles, each with a position, velocity and fittest position but how can we update this population to find our optimum spot. . Each particle could just move in the direction that they think the optimum spot is. But if they overshoot it or get lost, thankfully they remember their best position so they can use that a little bit too. . Particles&#39; social lives . Seems pretty inefficient for a bunch of these particles to all be trying the same thing without sharing any information with each other. In PSO, they can get &quot;fittest position&quot; from some other members of the population when they‚Äôre updating (called the social component). . They choose a few other particles and say ‚Äúhey I‚Äôm looking for this red marker, any chance you‚Äôve seen it? ‚Äú and the other particles reply ‚ÄúNo but here is where I was when I was closest to it.‚Äú. Thrilling conversations. . . Note: Intesting side note, PSO was introduced by James Kennedy and Russell Eberhart in 1995 after they discovered its optimisation properties while trying to build a social simulator. . Too much social interaction . A quick way to get stuck with a bad solution to a complex problem is to only listen to one suggestion and following that. This is what happens in particle swarm optimisation when all particles communicate to all of the particles during their update step (called the global component). . Update code . Here&#39;s the code for the Particle to update itself each iteration. . #collapse-hide def update(self, fittest_informant, global_fittest, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step): &quot;&quot;&quot; Updates the velocity and position of the particle using the PSO update algorithm&quot;&quot;&quot; self.position += self.velocity * scale_update_step cognitive = random.uniform(0, follow_personal_best) social = random.uniform(0, follow_social_best) glob = random.uniform(0, follow_global_best) self.velocity = (follow_current * self.velocity + cognitive * (self.fittest_position - self.position) + social * (fittest_informant.fittest_position - self.position) + glob * (global_fittest.fittest_position - self.position)) current_fitness = self.assess_fitness() if (current_fitness &lt; self.previous_fitness and self.previous_fitness is not None): self.fittest_position = self.position self.previous_fitness = current_fitness . . . Note: We are using a variant of the PSO algorithm introduced in 1995, with a social component as well as global. Also, we sample uniformly from 0 and our given update parameter before updating each part of the equation. . There are various values used to determine how to update the current velocity (as described above). . ` | cognitive is how much to use the particles current velocity. | social is how much to use it&#39;s the fittest position of a smaller subset of the population. | glob (global) is how much to use the fittest position of the fittest particle in the population. | . These are applied to the difference between the particles current position and a &quot;fit&quot; other position (either it&#39;s own fittest position or another particle&#39;s fittest position). . Particle Class . Here is the Particle class with the update and assess_fitness methods added in. . #collapse-hide class Particle: &quot;&quot;&quot; An Particle used in PSO. Attributes - problem : function to minimise velocity : nparray The current velocity of the particle position : nparray The current position of the particle, used as the solution for the problem given id : int The unique id of the particle Public Methods - assess_fitness() Determines the fitness of the particle using the given problem update(fittest_informant, global_fittest, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) Updates the velocity and position of the particle using the PSO update algorithm &quot;&quot;&quot; def __init__(self, problem, velocity, position, index): self.velocity = velocity self.position = position self.fittest_position = position self.problem = problem self.id = index self.previous_fitness = 1e7 def assess_fitness(self): &quot;&quot;&quot;Determines the fitness of the particle using the given problem&quot;&quot;&quot; return assess_fitness(self.position, self.problem) def update(self, fittest_informant, global_fittest, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step): &quot;&quot;&quot; Updates the velocity and position of the particle using the PSO update algorithm&quot;&quot;&quot; self.position += self.velocity * scale_update_step cognitive = random.uniform(0, follow_personal_best) social = random.uniform(0, follow_social_best) glob = random.uniform(0, follow_global_best) self.velocity = (follow_current * self.velocity + cognitive * (self.fittest_position - self.position) + social * (fittest_informant.fittest_position - self.position) + glob * (global_fittest.fittest_position - self.position)) current_fitness = self.assess_fitness() if (current_fitness &lt; self.previous_fitness): self.fittest_position = self.position self.previous_fitness = current_fitness . . Find the fittest Particle in the swarm . We use this find_current_best method to keep track of our current fittest Particle, and to find the best among a selected few &quot;informant&quot; Particles for the social component. . #collapse-show def find_current_best(swarm, problem): &quot;&quot;&quot;Evaluates a given swarm and returns the fittest particle based on their best previous position This can be sped up to only loop over swarm once, but because this is a tutorial, 3 lines is nicer. &quot;&quot;&quot; fitnesses = [assess_fitness(x.fittest_position, problem) for x in swarm] best_value = min(fitnesses) best_index = fitnesses.index(best_value) return swarm[best_index] . . PSO Class . This is just a wrapper which updates all the particles and keeps track of the current fittest. . . Note: One thing to note is that we randomly sample the swarm to get the &quot;informants&quot; for the social update in each particle. There are many different topologies that can be chosen for this part of the algorithm, but we&#8217;re keeping it simple here. . #collapse-hide class PSO: &quot;&quot;&quot; An implementation of Particle Swarm Optimisation, pioneered by Kennedy, Eberhart and Shi. The swarm consists of Particles with 2 fixed length vectors; velocity and position. Position is initialised with a uniform distribution between 0 and 1. Velocity is initialised with zeros. Each particle has a given number of informants which are randomly chosen at each iteration. Attributes - swarm_size : int The size of the swarm vector_length : int The dimensions of the problem, should be the same used when creating the problem object num_informants: int The number of informants used for social component in particle velocity update Public Methods - improve(follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) Update each particle in the swarm and updates the global fitness update_swarm(follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) Updates each particle, randomly choosing informants for each particle&#39;s update. update_global_fittest() Updates the `globale_fittest` variable to be the current fittest Particle in the swarm. &quot;&quot;&quot; def __init__(self, problem, swarm_size, vector_length, num_informants=2): self.swarm_size = swarm_size self.num_informants = num_informants self.problem = problem self.swarm = [Particle(self.problem, np.zeros(vector_length), np.random.rand(vector_length), i) for i, x in enumerate(range(swarm_size))] self.global_fittest = np.random.choice(self.swarm, 1)[0] def update_swarm(self, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step): &quot;&quot;&quot;Update each particle in the swarm&quot;&quot;&quot; for particle in self.swarm: informants = np.random.choice(self.swarm, self.num_informants) if particle not in informants: np.append(informants, particle) fittest_informant = find_current_best(informants, self.problem) particle.update(fittest_informant, self.global_fittest, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) def update_global_fittest(self): fittest = find_current_best(self.swarm, self.problem) global_fittest_fitness = self.global_fittest.assess_fitness() if (fittest.assess_fitness() &lt; global_fittest_fitness): self.global_fittest = fittest def improve(self, follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step): &quot;&quot;&quot;Improves the population for one iteration.&quot;&quot;&quot; self.update_swarm(follow_current, follow_personal_best, follow_social_best, follow_global_best, scale_update_step) self.update_global_fittest() size = 25 vector_length = 2 num_informants = 2 pso = PSO(problem, size, vector_length) . . &#160;Interaction . We&#39;re using Panel (a library from Anaconda) for the sliders and buttons. Because there are a lot of settings for PSO, we&#39;ll leave a escape hatch for people in the form of a reset_button which will set the sliders to their default. . Sliders and defaults . #collapse-hide default_pop_size = 25 default_time = 3 default_num_informants = 6 population_size_slider = pn.widgets.IntSlider(name=&#39;Population Size&#39;, start=10, end=50, value=default_pop_size) time_slider = pn.widgets.IntSlider(name=&#39;Time Evolving (s)&#39;, start=0, end=15, value=default_time) num_informants_slider = pn.widgets.IntSlider(name=&#39;Number of Informants&#39;, start=0, end=20, value=default_num_informants) default_current = 0.7 default_personal_best = 2.0 default_social_best = 0.9 default_global_best = 0.0 default_scale_update_step = 0.7 follow_current_slider = pn.widgets.FloatSlider(name=&#39;Follow Current&#39;, start=0.0, end=5, value=default_current) follow_personal_best_slider = pn.widgets.FloatSlider(name=&#39;Follow Personal Best&#39;, start=0, end=5, value=default_personal_best) follow_social_best_slider = pn.widgets.FloatSlider(name=&#39;Follow Social Best&#39;, start=0.0, end=5, value=default_social_best) follow_global_best_slider = pn.widgets.FloatSlider(name=&#39;Follow Global Best&#39;, start=0.0, end=1, value=default_global_best) scale_update_step_slider = pn.widgets.FloatSlider(name=&#39;Scale Update Step&#39;, start=0.0, end=1, value=0.7) reset_params_button = pn.widgets.Button(name=&#39;Reset Parameters&#39;, width=50) def reset_event(event): global default_current global default_personal_best global default_social_best global default_global_best global default_scale_update_step global default_pop_size global default_time global default_num_informants follow_current_slider.value, follow_personal_best_slider.value = default_current, default_personal_best follow_social_best_slider.value, follow_global_best_slider.value = default_social_best, default_global_best scale_update_step_slider.value, population_size_slider.value = default_scale_update_step, default_pop_size time_slider.value, num_informants_slider.value = default_time, default_num_informants reset_params_button.on_click(reset_event) . . Set the Target . For the &quot;click to set target&quot; interaction, we&#39;ll use a Holoviews DynamicMap. It sounds complicated but put simply, it links a stream with a callback function. In this case the stream we&#39;re using is a hv.stream.SingleTap, which will trigger the tap_event callback function with the x and y position of the tap when a tap happens. A hv.Points object is returned which can be displayed later. . #collapse-show def tap_event(x,y): global target_x global target_y if x is not None: target_x, target_y = x,y return hv.Points((x,y,1), label=&#39;Target&#39;).opts(color=&#39;r&#39;, marker=&#39;^&#39;, size=15) target_x, target_y = 0.5, 0.5 tap_stream = hv.streams.SingleTap(transient=True, x=target_x, y=target_y) target_tap = hv.DynamicMap(tap_event, streams=[tap_stream]) . . Create button events . Now for the best part, animating the Particles. This time our callback will return our swarm visualised using hv.Points for the particle points, hv.VectorField for the velocity arrows, and hv.Points to circle the fittest particle. . We&#39;re going to use a Holoviews DynamicMap again. This time, our stream that we link to the callback is one with no parameters so we can trigger it with our buttons. run_button creates a new population and uses DynamicMap&#39;s periodic method to keep updating it for a given period of time (set with a slider from above). If there&#39;s anything there you&#39;d like explained more, feel free to reach out to me on Twitter. . #collapse-show def update(): pso.improve(follow_current_slider.value, follow_personal_best_slider.value, follow_social_best_slider.value, follow_global_best_slider.value, scale_update_step_slider.value) vect_data = get_vectorfield_data(pso.swarm) vectorfield = hv.VectorField(vect_data, vdims=[&#39;Angle&#39;, &#39;Magnitude&#39;, &#39;Index&#39;]) particles = [np.array([vect_data[0], vect_data[1], vect_data[4]]) for i, particle in enumerate(swarm)] scatter = hv.Points(particles, vdims=[&#39;Index&#39;], group=&#39;Particles&#39;) fittest = hv.Points((pso.global_fittest.fittest_position[0], pso.global_fittest.fittest_position[1],1), label=&#39;Current Fittest&#39;) layout = vectorfield * scatter * fittest layout.opts( opts.Points(color=&#39;b&#39;, fill_alpha=0.1, line_width=1, size=10), opts.VectorField(color=&#39;Index&#39;, cmap=&#39;tab20c&#39;, magnitude=dim(&#39;Magnitude&#39;).norm()*10, pivot=&#39;tail&#39;), opts.Points(&#39;Particles&#39;, color=&#39;Index&#39;, cmap=&#39;tab20c&#39;, size=5, xlim=(0,1), ylim=(0,1)) ) return layout vector_field = hv.DynamicMap(update, streams=[Stream.define(&#39;Next&#39;)()]) run_button = pn.widgets.Button(name=&#39; u25b6 Begin Improving&#39;, width=50) def b(event): global pso size = population_size_slider.value vector_length = 2 num_informants = num_informants_slider.value pso_fitnesses = [] pso = PSO(problem, size, vector_length, num_informants) vector_field.periodic(0.005, timeout=time_slider.value) run_button.on_click(b) . . New Population Button . We&#39;ll also add a button which can step through the update process or reset the population. We do this by hooking up other buttons to the vector_field.streams DynamicMap and passing it to hv.streams.Stream.trigger. . #collapse-show def new_pop_event(event): global pso size = population_size_slider.value num_informants = num_informants_slider.value pso = PSO(problem, size, vector_length=2, num_informants=num_informants) hv.streams.Stream.trigger(vector_field.streams) new_pop_button = pn.widgets.Button(name=&#39;New Population&#39;, width=50) new_pop_button.on_click(new_pop_event) def next_gen_event(event): hv.streams.Stream.trigger(vector_field.streams) next_generation_button = pn.widgets.Button(name=&#39;Next Generation&#39;, width=50) next_generation_button.on_click(next_gen_event) . . Layout everything together . instructions = pn.pane.Markdown(&#39;&#39;&#39; # Partical Swarm Optimisation Dashboard ## Instructions: 1. **Click on the plot to place the target.** 2. Click &#39; u25b6 Begin Improving&#39; button to begin improving for the time on the Time Evolving slider. 3. Experiment with the sliders &#39;&#39;&#39;) dashboard = pn.Column(instructions, pn.Row((vector_field*target_tap).opts(width=600, height=600), pn.Column( pn.Row(run_button, pn.Spacer(width=50), new_pop_button), next_generation_button, time_slider, num_informants_slider, population_size_slider, follow_current_slider, follow_personal_best_slider, follow_social_best_slider, follow_global_best_slider, scale_update_step_slider, reset_params_button))) . dashboard . Conclusion . Particle Swarm Optimisation is a really intesting algorithm which was built while trying to build a simiplified model of social interactions. The original aim was to create an algorithm in which the particles would behave like flocking birds. . Each particle has a velocity and position, and the position represents a potential solution to your problem. For updating the velocities, each particle uses its current position, its own fittest position and the fittest positions of other particles. . We&#39;ve also looked at Anacondas&#39;s HoloViz tools (Holoviews, Panel and Bokeh). Using these we build an interactive dashboard which shows all the particles updating! . I personally love learning about these kind of algorithms and finding ways to interact with them visually. What do you think about these nature-inspired algorithms? Did you learn a bit about creating interactive visualisations in Python by reading this article? If so, feel free to share it, and you‚Äôre also more than welcome to contact me (via Twitter) if you have any questions, comments, or feedback. . Thanks for reading! :rocket: . Follow @_ScottCondron .",
            "url": "https://www.scottcondron.com/jupyter/optimisation/visualisation/2020/08/02/interactive-particle-swarm-optimisation-from-scratch-in-python.html",
            "relUrl": "/jupyter/optimisation/visualisation/2020/08/02/interactive-particle-swarm-optimisation-from-scratch-in-python.html",
            "date": " ‚Ä¢ Aug 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Interactive Genetic Algorithm Dashboard from Scratch in Python",
            "content": "What are we doing? . If you want to interact with the final result first, you can play with it on to PyViz examples here: https://genetic-algorithm.pyviz.demo.anaconda.com/GA . How can you maximise the number of components in a laptop, while having size, weight and price constraints? For questions like these, we often want to reach for optimisation algorithms, and one particularly fun one is Genetic Algorithm. . Genetic Algorithm is cool so I created an interactive Genetic Algorithm dashboard with @HoloViews and @Panel_org.Click to set a target and see the little critters evolve to be closest to it. Each time there is a generational update, the plot changes to show their positions. pic.twitter.com/5K9Ehp7wlo . &mdash; Scott Condron (@_ScottCondron) July 18, 2020 . Our example problem . For the sake of a fun visualisation, let&#39;s say the optimisation is &quot;Wherever I click on the plot is the optimimum spot to find&quot;. We&#39;re going to use a population-based approach, Genetic Algorithm, in which there is a population of individuals (each individual representing a possible solution) which evolve across generations. Each solution is just the individual&#39;s x and y coordinates. . What we want to see . We want to see a kind of &quot;evolution simulator&quot; in which we click a spot on the plot and when we begin evolving, each generation moves closer to the place we clicked. . We need a population . &quot;And God said, Let us make man in our image&quot;. First, let&#39;s create a population. . Imports . #collapse-hide import math import numpy as np import pandas as pd import random from holoviews import opts from matplotlib import pyplot as plt import holoviews as hv import panel as pn from holoviews.streams import Stream hv.extension(&#39;matplotlib&#39;, logo=False) . . Create Population . #collapse-show def create_population(population_size, vector_length): return np.random.rand(population_size, vector_length) population_size = 100 vector_length = 2 current_population = create_population(population_size, vector_length) hv.Scatter(current_population) . . Survival of the fittest . We&#39;re going to need to evolve individuals from our population, so we need some way to check which of the population is the fittest. . &#160;Closer (smaller distance) is better . For the sake of this visualisation, we&#39;re going to place a target on the plot and the &quot;fitness&quot; of a individual is how close they are to the target. We&#39;re going to calculate the distance using the euclidean distance metric. . #collapse-show def mean_squared_error(y_true, y_pred): return ((y_true - y_pred)**2).mean(axis=0) target_x, target_y = 0,0 def problem(soln): global target_x #using globals so we can link this to the click event later global target_y return mean_squared_error(soln, [target_x, target_y]) . . Then we need a way to check, who&#39;s our fittest member of our community . #collapse-show def assess_fitness(individual, problem): &quot;Determines the fitness of an individual using the given problem&quot; return problem(individual) def find_current_best(population, problem): &quot;&quot;&quot;Evaluates a given population and returns the fittest individual. This can be sped up to only loop over popuation once, but because this is a tutorial, 3 lines is nicer. &quot;&quot;&quot; fitnesses = [assess_fitness(x, problem) for x in population] best_value = min(fitnesses) # Lowest is best best_index = fitnesses.index(best_value) return population[best_index] . . aaaand Fight! . Now, we&#39;re going to let these potential solutions fight it out and only let a certain few have offspring. For this we will use &quot;Tournament Selection&quot; which is just grabbing a few individuals and having them compete to the death (the fittest survives!). . What&#39;s nice about this is that you can keep a bit of diversity within the population and it&#39;s not just the best that survive, some lucky unfit individuals might be matched up with worse folk, and so they&#39;ll survive. . #collapse-show def tournament_select_with_replacement(population, tournament_size, problem): &quot;Competes a number of challengers and returns the fittest one&quot; challengers_indexes = np.random.choice(population.shape[0], tournament_size, replace=True) challengers = population[challengers_indexes] return find_current_best(challengers, problem) . . Then once we have done this twice, those two individuals can &quot;mate&quot; and have children... to keep the population the same across generations for simplicity, they&#39;ll have two children. We&#39;ll use Two point Crossover), which is just splitting both parents in three parts and swapping the middle part to form two children. . #collapse-show def crossover(parent_a, parent_b): &quot;Performs two point crossover on two parents&quot; l = parent_a.shape[0] c, d = random.randint(0, l), random.randint(0, l) # Flip if c greater than d if (c &gt; d): d, c = c, d if (c == d): d += 1 temp = np.copy(parent_a) child_a = np.concatenate([parent_a[0:c], parent_b[c:d], parent_a[d:]]) child_b = np.concatenate([parent_b[0:c], temp[c:d], parent_b[d:]]) return child_a, child_b . . . Mutate! . For extra variety across generations, we want to introduce a bit of chaos to the system to produce the Marie Curie of each generation (but also probably our least capable individuals too). This helps find new solutions outside our current population&#39;s capability. So for each individual, there&#39;s a chance that their offspring will mutate (determined by mutation_rate). . #collapse-show def mutate(child, mutation_rate, mutation_scale): &quot;May mutate a child using Gaussian convolution&quot; if mutation_rate &gt;= random.uniform(0, 1): size = child.shape[0] mutation_value = np.random.normal(0, mutation_scale, size) child = child + mutation_value return child . . Here&#39;s the entirety of what happens to the population between generations. To recap: a bunch from the current population are selected at random to compete to reproduce. Two parents then produce two children using a mix of the two parents for both children. Finally, each child has a chance that they will mutate. One we&#39;ve created a new population of the same size as the original population, we have completed one &quot;generation&quot;. . #collapse-show def update_population(current_population, problem, should_mutate, mutation_rate, mutation_scale): &quot;&quot;&quot;Performs one generational update of Genetic Algorithm&quot;&quot;&quot; pop_size = len(current_population) next_population = np.empty((pop_size, 2)) tournament_size=2 for i in range(int(pop_size / 2)): parent_a = tournament_select_with_replacement(current_population, tournament_size, problem) parent_b = tournament_select_with_replacement(current_population, tournament_size, problem) child_a, child_b = crossover(parent_a, parent_b) next_population[i] = mutate(child_a, mutation_rate, mutation_scale) if should_mutate else child_a position_child_b = i + (pop_size / 2) next_population[int(position_child_b)] = mutate(child_b, mutation_rate, mutation_scale) if should_mutate else child_b return next_population . . A little class for saving the state of the evolution . #collapse-show class GeneticAlgorithm(object): def __init__(self, population_size, vector_length, problem): self.problem = problem self.current_population = create_population(population_size, vector_length) self.current_best = find_current_best(self.current_population, self.problem) def next_generation(self, mrate, mscale, should_mutate): self.current_population = update_population(self.current_population, self.problem, should_mutate, mrate, mscale) self.current_best = find_current_best(self.current_population, self.problem) ga = GeneticAlgorithm(population_size, vector_length, problem) . . Interact . The sliders, tap streams, and buttons for our dashboard. This is all using Holoviews and Panel. . Buttons . run_button begins a periodic update of our evolution process when the pn.widgets.Button is clicked. next_generation_button triggers just one generational update. new_pop_button triggers the creation of a new population. . Sliders and Layout . The rest are just pn.widgets.IntSlider or pn.widgets.FloatSlider sliders and markdown for the other bits and bobs. This is then positioned out using pn.Column, pn.Row and pn.Spacer from panel. . #collapse-show hv.extension(&#39;bokeh&#39;, logo=False) def tap_event(x,y): global target_x global target_y if x is not None: target_x, target_y = x,y return hv.Points((x,y,1), label=&#39;Target&#39;).opts(color=&#39;r&#39;, marker=&#39;^&#39;, size=10) target_x, target_y = 10, -10 tap = hv.streams.SingleTap(transient=True, x=target_x, y=target_y) tap_dmap = hv.DynamicMap(tap_event, streams=[tap]) mutate_checkbox = pn.widgets.Checkbox(name=&#39;Mutate&#39;, value=True) niters_slider = pn.widgets.IntSlider(name=&#39;Time Evolving (s)&#39;, start=0, end=50, value=5) mutation_rate_slider = pn.widgets.FloatSlider(name=&#39;Mutation Rate&#39;, start=0.0, end=1.0, value=0.3) mutation_scale_slider = pn.widgets.IntSlider(name=&#39;Mutation Scale&#39;, start=0, end=50, value=1) new_pop_button = pn.widgets.Button(name=&#39;New Population&#39;, width=50) def e(event): global ga population_size = 100 vector_length = 2 ga = GeneticAlgorithm(population_size, vector_length, problem) hv.streams.Stream.trigger(pso_scatter.streams) new_pop_button.on_click(e) next_generation_button = pn.widgets.Button(name=&#39;Next Generation&#39;, width=50) def next_gen_event(event): hv.streams.Stream.trigger(pso_scatter.streams) next_generation_button.on_click(next_gen_event) def update(): ga.next_generation(mutation_rate_slider.value, mutation_scale_slider.value, mutate_checkbox.value) pop_scatter = hv.Scatter(ga.current_population, label=&#39;Population&#39;) best_points = hv.Points((ga.current_best[0], ga.current_best[1], 1), label=&#39;Current Fittest&#39;) merged = pop_scatter * best_points merged.opts( opts.Scatter(color=&#39;b&#39;), opts.Points(color=&#39;c&#39;, size=10) ) return merged pso_scatter = hv.DynamicMap(update, streams=[Stream.define(&#39;Next&#39;)()]) run_button = pn.widgets.Button(name=&#39; u25b6 Begin Evolving&#39;, width=50) def b(event): pso_scatter.periodic(0.1, timeout=niters_slider.value, block=False) run_button.on_click(b) instructions = pn.pane.Markdown(&#39;&#39;&#39; # Genetic Algorithm Dashboard ## Instructions: 1. **Click on the plot to place the target.** 2. Click &#39; u25b6 Begin Evolution&#39; button to begin evolving for the time on the Time Evolving slider. 3. Experiment with the Mutation Rate (the probability of an individual in the next generation mutating) 4. Experiment with the Mutation Scale (the size of the mutation, tip: zoom out using the Wheel Zoom on the right of the plot). &#39;&#39;&#39;) combined_dashboard = pso_scatter*tap_dmap dashboard = pn.Column(instructions, pn.Row(combined_dashboard.opts(width=600, height=600), pn.Column( pn.Row(run_button, pn.Spacer(width=50), new_pop_button), next_generation_button, mutate_checkbox, niters_slider, mutation_rate_slider, mutation_scale_slider))) #¬†dashboard # uncomment this to view the dashboard . . . Play with it yourself! . Here it is deployed on PyViz examples: https://genetic-algorithm.pyviz.demo.anaconda.com/GA. . You can also view and run all the code yourself from here. Thanks for reading. . Follow me on Twitter here for more stuff like this. . Follow @_ScottCondron .",
            "url": "https://www.scottcondron.com/jupyter/optimisation/visualisation/2020/07/20/interactive-genetic-algorithm-dashboard-from-scratch-in-python.html",
            "relUrl": "/jupyter/optimisation/visualisation/2020/07/20/interactive-genetic-algorithm-dashboard-from-scratch-in-python.html",
            "date": " ‚Ä¢ Jul 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "This blog post was written in a Jupyter Notebook",
            "content": "Why should I care? . I think it&#39;s kind of cool that you can write text beside snippets of code that actually run and automatically have the output of your code display alongside it. . A quick example: . Say I want to describe a function that plots a sine wave at different amplitudes. . First, I would define the function . import matplotlib.pyplot as plt import numpy as np def plot_sin(amplitude=1): &#39;&#39;&#39;Plot a sine wave of a given amplitude&#39;&#39;&#39; time = np.arange(0, 10, 0.1) y = np.sin(time) plt.plot(time, amplitude*y) plt.ylabel(&#39;Amplitude&#39;) plt.xlabel(&#39;Time (s)&#39;) plt.show() . Then, just after defining it, I could call it with different arguments and display the outputs alongside any text. . Sine wave with the default amplitude of 1 . plot_sin() . Sine wave with an amplitude of 20 . plot_sin(amplitude=20) . All of the above was written and ran within a Jupyter Notebook and automatically formatted for this blogpost. I didn&#39;t have to have some scripts lying around to create the images in the post. I didn&#39;t have to save, upload and link to the images. I didn&#39;t have to worry that the code examples wouldn&#39;t run. . You can also paste images as you would expect. . . How is that possible? . It&#39;s a mix and match of a few different tools. . Namely: . Jupyter Notebooks | fast-template | Github Pages | Jekyll | nbdev | . Jupyter Notebooks . I&#39;m imagining most people reading this will know what Jupyter Notebooks are. From their website: . The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. . fast-template . The repo was first created from the fast-template repo from fast.ai&#39;s Jeremy Howard. This is a simplified way to generate a blog and host it using Github Pages. You can write your posts in Markdown Language and when you commit them to your repo, they will be converted to html for your blog using Jekyll. . nbdev . nbdev is a really powerful library which isn&#39;t being used to it&#39;s fullest potential here. It&#39;s a tool to create entire python libraries, a website hosting your documentation and way to automatically run tests... all using Jupyter Notebooks. . But for this project, it&#39;s being used to export output cells and any uploaded attachment from Jupyter Notebooks to markdown using nbdev_detach *.ipynb and nbdev_nb2md to convert notebooks to markdown. It&#39;s also being used to remove metadata from the notebooks during git commits, which helps reducing the change of merge conflicts. That last feature is probably overkill because I don&#39;t think I&#39;ll be doing a lot of merging. . Github Actions . Last but not least, Github Actions runs all of the above during each commit automatically! See here for the config. This is mostly taken from nbdev with a few things changed. . Thanks for reading . If you&#39;d like, you can find this blogs github repo here or follow me on Twitter here . A huge thanks to Jeremy Howard at fastai for making fast-template and nbdev which is doing all of the hard work to bring all these tools together! .",
            "url": "https://www.scottcondron.com/jupyter/blogging/visualisation/2020/01/20/this-blog-post-was-written-in-a-jupyter-notebooks.html",
            "relUrl": "/jupyter/blogging/visualisation/2020/01/20/this-blog-post-was-written-in-a-jupyter-notebooks.html",
            "date": " ‚Ä¢ Jan 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Begin creating Deep Learning¬†models.",
            "content": "Following the advice of Julia Evans, I&#39;m going to write about things that I wish I knew a year ago. Machine Learning research sometimes feels like an activity reserved for the intellectually superior, while us mere mortals enjoy their trimmings when they publish and the open-source community implements it. . . You don&#39;t need a&#160;PhD . This myth was completely debunked for me when I took the fast.ai course, Practical Deep Learning for Coders, v3. So my first tip, do it. Also, this post by Rachel Thomas gives some great advice to those thinking about grad school. . If some of the stuff below seems like gibberish, fast.ai is a good place to go. . Tips for people wanting to begin creating / improving deep learning&#160;models. . Find a dataset that interests you. Here&#39;s a good post about where to find it. Try not to get analysis paralysis, just choose one. You&#39;re not married to the dataset you choose, but get to know it. . Here are plenty of resources to learn to visualize and analyze a dataset. . Use Google&#160;Colab . If you want free access to a GPU, here you go. If you want to know why or setting up a GPU is becoming frustrating. . Get 100% accuracy on one instance/batch of your&#160;data . Rather than wasting your time loading all of the data each time you want to check for bugs, create a tiny dataset with just one instance of your dataset and overfit it with a very simple model. . &#160;Get 100% accuracy on around 10% of your&#160;data . Once you can overfit your model on one instance, begin using more of your data and try to overfit it by adding more layers. Don&#39;t use any regularization for the moment (e.g., Dropout, L1/ L2 regularization), this is another sanity preserving tip so you know that your model is learning. . &#160;Add all of your training&#160;data . Once you add all of your data, if training is taking too long, leave it aside as an experiment and continue your work on the 10% of data. If you&#39;re overfitting when you add more layers and all of your data, here&#39;s five steps to reduce overfitting. . . And that&#39;s it for today, those tips are some of the valuable gems that I wish I found out sooner. If have any feedback, here&#39;s me on Twitter. . Thanks for reading .",
            "url": "https://www.scottcondron.com/deep%20learning/ai/2020/01/17/begin-creating-dl-models.html",
            "relUrl": "/deep%20learning/ai/2020/01/17/begin-creating-dl-models.html",
            "date": " ‚Ä¢ Jan 17, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I‚Äôm from Dublin, Ireland üáÆüá™ and living in Edinburgh, Scotland üè¥Û†ÅßÛ†Å¢Û†Å≥Û†Å£Û†Å¥Û†Åø . I‚Äôm currently interested in Deep Learning with Audio, Python software development and bits and bobs from lots of other areas. . I was working as a web/mobile software developer for a few years and then went back to university to do an MSc in AI in Heriot Watt University, Edinburgh. . I‚Äôm now working as a Research Engineer in Speech Graphics . You can follow me on Twitter here. .",
          "url": "https://www.scottcondron.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://www.scottcondron.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}